{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"E:/github_repo/AEs/\")\n",
    "from AEs_module import *\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import ipywidgets as pyw\n",
    "import tkinter.filedialog as tkf\n",
    "import tifffile\n",
    "from tabulate import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import linalg as LA\n",
    "plt.rcParams['font.family'] = 'Cambria'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_adr = tkf.askopenfilenames()\n",
    "print(*file_adr, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load = load_data(file_adr, dat_dim=3, dat_unit='eV', cr_range=[1.0, 3.56, 0.01], dat_scale=1.0, rescale=False, DM_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning (optional)\n",
    "# rescale_0to1: rescale each data from 0 to 1\n",
    "bin_y = 4 # binning size (height)\n",
    "bin_x = 4 # binning size (width)\n",
    "str_y = 4 # stride height-direction\n",
    "str_x = 4 # stride width-direction\n",
    "\n",
    "data_load.binning(bin_y, bin_x, str_y, str_x, offset=0, rescale_0to1=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load.make_input(min_val=0.0, max_normalize=True, rescale_0to1=False, final_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"%d gpu available\"%(torch.cuda.device_count()))\n",
    "    cuda_device = torch.device(\"cuda:0\")\n",
    "    print(torch.cuda.get_device_name(cuda_device))\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "    print(torch.cuda.memory_summary(device=cuda_device))\n",
    "else:\n",
    "    cuda_device = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comp = 5\n",
    "channels = [8, 16, 32, num_comp]\n",
    "kernels = [64, 32, 16, 0]\n",
    "pooling = [2, 2, 2, 2]\n",
    "\n",
    "dat_dim = []\n",
    "tmp_dim = data_load.num_dim\n",
    "for i in range(len(kernels)):\n",
    "    tmp_dim += (-kernels[i]+1)\n",
    "    tmp_dim /= pooling[i]\n",
    "    dat_dim.append(int(tmp_dim))\n",
    "    \n",
    "kernels[-1] = dat_dim[-2] - pooling[-1] + 1\n",
    "dat_dim[-1] = 1\n",
    "\n",
    "print(dat_dim)\n",
    "print(kernels)\n",
    "print(channels)\n",
    "print(pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_ = False\n",
    "\n",
    "enc_model = CAE1D_encoder(data_load.num_dim, channels, kernels, pooling)\n",
    "\n",
    "if parallel_:\n",
    "    enc_model = nn.DataParallel(enc_model)\n",
    "    \n",
    "enc_model.cuda(cuda_device)\n",
    "for p in enc_model.parameters():\n",
    "    if p.requires_grad:\n",
    "        print(p.data.shape)\n",
    "train_params = sum(p.numel() for p in enc_model.parameters() if p.requires_grad)\n",
    "print(train_params)\n",
    "print(enc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_model = linFE_decoder(num_comp, data_load.num_dim)\n",
    "\n",
    "if parallel_:\n",
    "    dec_model = nn.DataParallel(dec_model)\n",
    "\n",
    "dec_model.cuda(cuda_device)\n",
    "print(dec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 970\n",
    "mini_batches = [data_load.dataset_input[k:k+batch_size] for k in range(0, len(data_load.dataset_input), batch_size)]\n",
    "print(len(mini_batches))\n",
    "print(len(mini_batches[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rate = 0.001\n",
    "\n",
    "params = list(enc_model.parameters()) + list(dec_model.parameters())\n",
    "optimizer = optim.Adam(params)\n",
    "\n",
    "torch.nn.init.orthogonal_(dec_model.decoder[0].weight)\n",
    "#torch.nn.init.xavier_normal_(model.decoder[0].weight)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "n_epoch = 50\n",
    "\n",
    "ae_coeffs = []\n",
    "ae_bias = []\n",
    "ce_losses = []\n",
    "mse_losses = []\n",
    "for epoch in range(n_epoch):\n",
    "    tmp_ce = 0\n",
    "    tmp_mse = 0\n",
    "    for i, m_batch in enumerate(mini_batches):\n",
    "        \n",
    "        x = torch.from_numpy(mini_batches[i])\n",
    "        x = x.to(torch.float32)\n",
    "        x = x.to(cuda_device)\n",
    "        x.requires_grad_(requires_grad=False)\n",
    "        \n",
    "        encoded = enc_model(x)\n",
    "        decoded = dec_model(encoded)\n",
    "        \n",
    "        #ce_loss = F.binary_cross_entropy(decoded, x, reduction=\"mean\")\n",
    "        #tmp_ce += ce_loss.item()\n",
    "        mse_loss = F.mse_loss(decoded, x, reduction=\"mean\")\n",
    "        tmp_mse += mse_loss.item()\n",
    "        \n",
    "        main_loss = mse_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        main_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        dec_model.decoder[0].weight.data.clamp_(min=0.0)\n",
    "        \n",
    "        if epoch == n_epoch-1:\n",
    "            coeff_batch = encoded.data.cpu().numpy().tolist()\n",
    "            ae_coeffs.extend(coeff_batch)            \n",
    "    \n",
    "    ce_losses.append(tmp_ce)\n",
    "    mse_losses.append(tmp_mse)\n",
    "    \n",
    "    if epoch == 0:\n",
    "        print(torch.cuda.memory_summary(device=cuda_device))\n",
    "    \n",
    "    if (epoch+1) % int(n_epoch/10) == 0:\n",
    "        print(tabulate([\n",
    "                        [\"epoch\", epoch+1], \n",
    "                        [\"loss\", main_loss.item()],\n",
    "                        ]))\n",
    "        print(\"%.2f minutes have passed\"%((time.time()-start)/60))\n",
    "        \n",
    "        fig, ax = plt.subplots(1, num_comp, figsize=(5*num_comp, 5))\n",
    "        for i in range(num_comp):\n",
    "            ax[i].plot(data_load.dat_dim_range, dec_model.decoder[0].weight.data.cpu()[:, i])\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"The training has been finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_coeffs = np.asarray(ae_coeffs)\n",
    "ae_comp_vectors = dec_model.decoder[0].weight.data.cpu().numpy().T\n",
    "print(ae_coeffs.shape)\n",
    "print(ae_comp_vectors.shape)\n",
    "\n",
    "# convert the coefficient matrix into coefficient maps\n",
    "coeffs = np.zeros_like(ae_coeffs)\n",
    "coeffs[data_load.ri] = ae_coeffs.copy()\n",
    "coeffs_reshape = reshape_coeff(coeffs, data_load.data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_ind = np.argmax(ae_comp_vectors, axis=1)\n",
    "peak_pos = data_load.dat_dim_range[peak_ind]\n",
    "peak_order = np.argsort(peak_pos)\n",
    "print(peak_pos)\n",
    "print(peak_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a customized colorbar\n",
    "color_rep = [\"black\", \"red\", \"green\", \"blue\", \"purple\", \"orange\"]\n",
    "print(len(color_rep))\n",
    "custom_cmap = mcolors.ListedColormap(color_rep)\n",
    "bounds = np.arange(-1, len(color_rep))\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=len(color_rep))\n",
    "sm = cm.ScalarMappable(cmap=custom_cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "cm_rep = [\"Greys\", \"Reds\", \"Greens\", \"Blues\", \"Purples\", \"Oranges\"]\n",
    "print(len(cm_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize loading vectors\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10)) # all loading vectors\n",
    "for i in range(num_comp):\n",
    "    ax.plot(data_load.dat_dim_range, ae_comp_vectors[i], \"-\", c=color_rep[np.where(peak_order==i)[0][0]], label=\"loading vector %d\"%(i+1), linewidth=5)\n",
    "#ax.grid()\n",
    "#ax.legend(fontsize=\"large\")\n",
    "ax.set_xlabel(\"Energy Loss (eV)\", fontsize=30)\n",
    "ax.set_ylabel(\"Intensity (arb. unit)\", fontsize=30)\n",
    "ax.tick_params(axis=\"both\", labelsize=30)\n",
    "#ax.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize coefficient maps\n",
    "for i in range(num_comp):\n",
    "    fig, ax = plt.subplots(1, data_load.num_img, figsize=(120, 10))\n",
    "    min_val = np.min(coeffs[:, i])\n",
    "    max_val = np.max(coeffs[:, i])\n",
    "    for j in range(data_load.num_img):\n",
    "        tmp = ax[j].imshow(coeffs_reshape[j][:, :, i], \n",
    "                               vmin=min_val, vmax=max_val, cmap=cm_rep[np.where(peak_order==i)[0][0]])\n",
    "        #ax[j].set_title(\"loading vector %d map\"%(i+1), fontsize=10)\n",
    "        ax[j].axis(\"off\")\n",
    "    fig.tight_layout()\n",
    "    #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize colorbars\n",
    "for i in range(num_comp):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    min_val = np.min(coeffs[:, i])\n",
    "    max_val = np.max(coeffs[:, i])\n",
    "    for j in range(1):\n",
    "        tmp = ax.imshow(np.zeros((10, 10)), \n",
    "                               vmin=min_val, vmax=max_val, cmap=cm_rep[np.where(peak_order==i)[0][0]])\n",
    "        #ax[j].set_title(\"loading vector %d map\"%(i+1), fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "    c_bar = fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "    c_bar.ax.tick_params(labelsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D subspace\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "\n",
    "def projection(c1, c2):\n",
    "    ax.cla()\n",
    "    ax.scatter(coeffs[:, c1], coeffs[:, c2], s=30, c=\"black\", alpha=0.5)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"loading vector %d\"%(c1+1), fontsize=15)\n",
    "    ax.set_ylabel(\"loading vector %d\"%(c2+1), fontsize=15)\n",
    "    ax.tick_params(axis=\"both\", labelsize=15)\n",
    "    fig.canvas.draw()\n",
    "    fig.tight_layout()\n",
    "\n",
    "x_widget = pyw.IntSlider(min=0, max=num_comp-1, step=1, value=0)\n",
    "y_widget = pyw.IntSlider(min=0, max=num_comp-1, step=1, value=1)\n",
    "\n",
    "pyw.interact(projection, c1=x_widget, c2=y_widget)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
