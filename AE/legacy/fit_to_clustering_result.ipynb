{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dimensionality reduction and unsupervised clustering for EELS-SI\n",
    "Miyoung Kim (corresponding author, mkim@snu.ac.kr)<br>\n",
    "Jinseok Ryu (jinseuk56@gmail.com), Hyeohn Kim, Ryeong Myeong Kim, Sungtae Kim, Ki Tae Nam, Young-Chang Joo<br>\n",
    "Dept. of Materials Science and Engineering, Seoul National University<br>\n",
    "https://doi.org/10.1016/j.ultramic.2021.113314<br>\n",
    "### last update 20210719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J. Ryu, Electron Microscopy and Spectroscopy Lab., Seoul National University\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import ListedColormap\n",
    "import hyperspy.api as hys\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import OPTICS\n",
    "import tkinter.filedialog as tkf\n",
    "import tifffile\n",
    "import ipywidgets as pyw\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a customized colorbar\n",
    "color_rep = [\"black\", \"red\", \"green\", \"blue\", \"orange\", \"purple\", \"yellow\", \"lime\", \n",
    "             \"cyan\", \"magenta\", \"lightgray\", \"peru\", \"springgreen\", \"deepskyblue\", \n",
    "             \"hotpink\", \"darkgray\"]\n",
    "print(len(color_rep))\n",
    "custom_cmap = mcolors.ListedColormap(color_rep)\n",
    "bounds = np.arange(-1, len(color_rep))\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=len(color_rep))\n",
    "sm = cm.ScalarMappable(cmap=custom_cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "cm_rep = [\"gray\", \"Reds\", \"Greens\", \"Blues\", \"Oranges\", \"Purples\"]\n",
    "print(len(cm_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_one_rescale(spectrum):\n",
    "    \"\"\"\n",
    "    normalize one spectrum from 0.0 to 1.0\n",
    "    \"\"\"\n",
    "    spectrum = spectrum.clip(min=0.0)\n",
    "    min_val = np.min(spectrum)\n",
    "    \n",
    "    rescaled = spectrum - min_val\n",
    "    \n",
    "    if np.max(rescaled) != 0:\n",
    "        rescaled = rescaled / np.max(rescaled)\n",
    "    \n",
    "    return rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threed_roll_axis(img):\n",
    "    stack = np.rollaxis(img, 2, 0)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(adr, rescale=False, crop=None, roll_axis=False):\n",
    "    \"\"\"\n",
    "    load a spectrum image\n",
    "    \"\"\"\n",
    "    storage = []\n",
    "    shape = []\n",
    "    for i, adr in enumerate(adr):\n",
    "        if crop:\n",
    "            temp = hys.load(adr)\n",
    "            print(temp.axes_manager[2])\n",
    "            temp = temp.isig[crop[0]:crop[1]]\n",
    "            temp = temp.data\n",
    "            print(temp.shape)\n",
    "        \n",
    "        else:\n",
    "            temp = hys.load(adr).data\n",
    "            if roll_axis:\n",
    "                temp = threed_roll_axis(temp)\n",
    "            print(temp.shape)\n",
    "            \n",
    "        if rescale:\n",
    "            for j in range(temp.shape[0]):\n",
    "                for k in range(temp.shape[1]):\n",
    "                    temp[j, k] = zero_one_rescale(temp[j, k])\n",
    "        shape.append(temp.shape)\n",
    "        storage.append(temp)\n",
    "    \n",
    "    shape = np.asarray(shape)\n",
    "    return storage, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning_SI(si, bin_y, bin_x, str_y, str_x, offset, depth, rescale=True):\n",
    "    \"\"\"\n",
    "    re-bin a spectrum image\n",
    "    \"\"\"\n",
    "    si = np.asarray(si)\n",
    "    rows = range(0, si.shape[0]-bin_y+1, str_y)\n",
    "    cols = range(0, si.shape[1]-bin_x+1, str_x)\n",
    "    new_shape = (len(rows), len(cols))\n",
    "    \n",
    "    binned = []\n",
    "    for i in rows:\n",
    "        for j in cols:\n",
    "            temp_sum = np.mean(si[i:i+bin_y, j:j+bin_x, offset:(offset+depth)], axis=(0, 1))\n",
    "            if rescale:\n",
    "                binned.append(zero_one_rescale(temp_sum))\n",
    "            else:\n",
    "                binned.append(temp_sum)\n",
    "            \n",
    "    binned = np.asarray(binned).reshape(new_shape[0], new_shape[1], depth)\n",
    "    \n",
    "    return binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_coeff(coeffs, new_shape):\n",
    "    \"\"\"\n",
    "    reshape a coefficient matrix to restore the original scanning shapes.\n",
    "    \"\"\"\n",
    "    coeff_reshape = []\n",
    "    for i in range(len(new_shape)):\n",
    "        temp = coeffs[:int(new_shape[i, 0]*new_shape[i, 1]), :]\n",
    "        coeffs = np.delete(coeffs, range(int(new_shape[i, 0]*new_shape[i, 1])), axis=0)\n",
    "        temp = np.reshape(temp, (new_shape[i, 0], new_shape[i, 1], -1))\n",
    "        #print(temp.shape)\n",
    "        coeff_reshape.append(temp)\n",
    "        \n",
    "    return coeff_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_arrangement(label_arr, new_shape):\n",
    "    \"\"\"\n",
    "    reshape a clustering result obtained by performing OPTICS\n",
    "    \"\"\"\n",
    "    label_sort = np.unique(label_arr)\n",
    "    #print(label_sort)\n",
    "    num_label = len(label_sort)\n",
    "    hist, edge = np.histogram(label_arr, bins=num_label)\n",
    "    #print(hist)\n",
    "    label_reshape = reshape_coeff(label_arr.reshape(-1, 1), new_shape)\n",
    "    \n",
    "    for i in range(len(label_reshape)):\n",
    "        label_reshape[i] = np.squeeze(label_reshape[i])\n",
    "        \n",
    "    selected = []\n",
    "    for i in range(num_label):\n",
    "        temp = []\n",
    "        for j in range(len(label_reshape)):\n",
    "            img_temp = np.zeros_like(label_reshape[j])\n",
    "            img_temp[np.where(label_reshape[j] == label_sort[i])] = 1.0\n",
    "            temp.append(img_temp)\n",
    "        selected.append(temp)    \n",
    "        \n",
    "    return label_reshape, selected, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_adr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_adr.extend(tkf.askopenfilenames())\n",
    "print(len(file_adr))\n",
    "print(*file_adr, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_img = len(file_adr)\n",
    "print(num_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spectrum images\n",
    "cr_range = [0.1, 5.0, 0.01] # reference\n",
    "data_original, shape_original = data_load(file_adr, rescale=False, crop=cr_range, roll_axis=False)\n",
    "print(len(data_original))\n",
    "print(shape_original)\n",
    "\n",
    "e_range_original = np.arange(cr_range[0], cr_range[1], cr_range[2])\n",
    "print(len(e_range_original))\n",
    "\n",
    "# load spectrum images\n",
    "cr_range = [0.5, 3.5, 0.01] # actual input\n",
    "data_storage, data_shape = data_load(file_adr, rescale=False, crop=cr_range, roll_axis=False)\n",
    "print(len(data_storage))\n",
    "print(data_shape)\n",
    "\n",
    "e_range = np.arange(cr_range[0], cr_range[1], cr_range[2])\n",
    "print(len(e_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-bin spectrum images in order to mitigate noises\n",
    "bin_y = 1 # binning size (height)\n",
    "bin_x = 1 # binning size (width)\n",
    "str_y = 1 # stride height-direction\n",
    "str_x = 1 # stride width-direction\n",
    "\n",
    "# reference\n",
    "dataset_original = []\n",
    "shape_new_original = []\n",
    "\n",
    "offset = 0\n",
    "depth_original = len(e_range_original)\n",
    "for img in data_original:\n",
    "    print(img.shape)\n",
    "    processed = binning_SI(img, bin_y, bin_x, str_y, str_x, offset, depth_original, rescale=False)\n",
    "    print(processed.shape)\n",
    "    shape_new_original.append(processed.shape)\n",
    "    dataset_original.append(processed)\n",
    "    \n",
    "shape_new_original = np.asarray(shape_new_original)\n",
    "print(shape_new_original)\n",
    "\n",
    "# actual input\n",
    "dataset = []\n",
    "data_shape_new = []\n",
    "offset = 0\n",
    "depth = len(e_range)\n",
    "for img in data_storage:\n",
    "    print(img.shape)\n",
    "    processed = binning_SI(img, bin_y, bin_x, str_y, str_x, offset, depth, rescale=True) # include the step for re-scaling the actual input\n",
    "    print(processed.shape)\n",
    "    data_shape_new.append(processed.shape)\n",
    "    dataset.append(processed)\n",
    "    \n",
    "data_shape_new = np.asarray(data_shape_new)\n",
    "print(data_shape_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_original_flat = []\n",
    "for i in range(num_img):\n",
    "    dataset_original_flat.extend(dataset_original[i].clip(min=0.0).reshape(-1, depth_original).tolist())\n",
    "    \n",
    "dataset_original_flat = np.asarray(dataset_original_flat)\n",
    "print(dataset_original_flat.shape)\n",
    "\n",
    "# create the input dataset\n",
    "dataset_flat = []\n",
    "for i in range(num_img):\n",
    "    dataset_flat.extend(dataset[i].clip(min=0.0).reshape(-1, depth).tolist())\n",
    "    \n",
    "dataset_flat = np.asarray(dataset_flat)\n",
    "print(dataset_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = len(dataset_flat)\n",
    "ri = np.random.choice(total_num, total_num, replace=False)\n",
    "\n",
    "dataset_input = dataset_flat[ri]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dimensionality reduction (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_num_comp = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF decomposition (linear dimensionality reduction)\n",
    "# please visit the below link for detailed information on NMF\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html?highlight=nmf#sklearn.decomposition.NMF\n",
    "\n",
    "skl_nmf = NMF(n_components=nmf_num_comp, init=\"nndsvda\", solver=\"mu\", max_iter=2000, \n",
    "              verbose=True, beta_loss=\"frobenius\", l1_ratio=0.0, alpha=0.0)\n",
    "\n",
    "skl_coeffs = skl_nmf.fit_transform(dataset_input)\n",
    "skl_comp_vectors = skl_nmf.components_\n",
    "print(skl_coeffs.shape)\n",
    "print(skl_comp_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the coefficient matrix into coefficient maps\n",
    "num_comp = nmf_num_comp\n",
    "coeffs = np.zeros_like(skl_coeffs)\n",
    "coeffs[ri] = skl_coeffs.copy()\n",
    "coeffs_reshape = reshape_coeff(coeffs, data_shape_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize loading vectors\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4)) # all loading vectors\n",
    "for i in range(nmf_num_comp):\n",
    "    ax[0].plot(e_range, skl_comp_vectors[i], \"-\", c=color_rep[i+1], label=\"loading vector %d\"%(i+1))\n",
    "ax[0].grid()\n",
    "ax[0].legend(fontsize=\"large\")\n",
    "ax[0].set_xlabel(\"eV\", fontsize=10)\n",
    "ax[0].tick_params(axis=\"x\", labelsize=10)\n",
    "ax[0].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "sel_nmf_comp = [2, 3, 4, 5] # choose several loading vectors to visualize\n",
    "for i in sel_nmf_comp:\n",
    "    ax[1].plot(e_range, skl_comp_vectors[i-1], \"-\", c=color_rep[i], label=\"loading vector %d\"%(i))\n",
    "ax[1].grid()\n",
    "ax[1].legend(fontsize=\"large\")\n",
    "ax[1].set_xlabel(\"eV\", fontsize=10)\n",
    "ax[1].tick_params(axis=\"x\", labelsize=10)\n",
    "ax[1].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the coefficient maps\n",
    "min_val = np.min(coeffs)\n",
    "max_val = np.max(coeffs)\n",
    "if num_img != 1:\n",
    "    for i in range(num_comp):\n",
    "        fig, ax = plt.subplots(1, num_img, figsize=(7*num_img, 7))\n",
    "        for j in range(num_img):\n",
    "            tmp = ax[j].imshow(coeffs_reshape[j][:, :, i], vmin=min_val, vmax=max_val, cmap=\"afmhot\")\n",
    "            ax[j].set_title(\"loading vector %d map\"%(i+1), fontsize=10)\n",
    "            ax[j].axis(\"off\")\n",
    "            fig.colorbar(tmp, cax=fig.add_axes([0.88, 0.15, 0.04, 0.7]))\n",
    "        plt.show()\n",
    "else:            \n",
    "    for i in range(num_comp):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7, 7*num_img))\n",
    "        tmp = ax.imshow(coeffs_reshape[0][:, :, i], vmin=min_val, vmax=max_val, cmap=\"afmhot\")\n",
    "        ax.set_title(\"loading vector %d map\"%(i+1), fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "        fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nonlinear dimensionality reduction (t-SNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE (non-linear dimensionality reduction)\n",
    "# apply t-SNE to the coefficient matrix produced by NMF decomposition\n",
    "# please visit the below link for detailed information on t-SNE\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html?highlight=tsne#sklearn.manifold.TSNE\n",
    "start = time.time()\n",
    "#perplex = [30, 35, 40, 45, 50]\n",
    "#perplex = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50] # try several perplexities\n",
    "perplex = [50]\n",
    "embeddings = []\n",
    "num_comp_vis = 2 # number of dimensions of final data before clustering\n",
    "for order, p in enumerate(perplex):\n",
    "    tmp_tsne = TSNE(n_components=num_comp_vis, perplexity=p, early_exaggeration=5.0, learning_rate=300.0, \n",
    "                init=\"random\", n_iter=1000, verbose=0)\n",
    "    tmp_tsne.fit_transform(coeffs)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(tmp_tsne.embedding_[:, 0], tmp_tsne.embedding_[:, 1], s=1, c=\"black\")\n",
    "    plt.title(\"perplexity %.1f\"%perplex[order])\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    embeddings.append(tmp_tsne.embedding_)\n",
    "    print(\"%d perplexity %.1f finished\"%(order, p))\n",
    "    print(\"%.2f min have passed\"%((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D results depending on perplexity\n",
    "fig, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
    "for i, ai in enumerate(ax.flat):\n",
    "    ai.scatter(embeddings[i][:, 0], embeddings[i][:, 1], s=1, c=\"black\")\n",
    "    ai.set_title(\"perplexity %.1f\"%perplex[i])\n",
    "    ai.grid()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D result selected\n",
    "sel_ind = 0\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.scatter(embeddings[sel_ind][:, 0], embeddings[sel_ind][:, 1], s=3, c=\"black\", alpha=0.5)\n",
    "ax.set_title(\"perplexity %.1f\"%(perplex[sel_ind]))\n",
    "#ax.grid()\n",
    "#ax.axis(\"off\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unsupervised clustering (OPTICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a data matrix for clustering after performing t-SNE\n",
    "num_comp = num_comp_vis\n",
    "coeffs = embeddings[sel_ind].copy()\n",
    "\n",
    "comp_axes = np.arange(num_comp)\n",
    "#comp_axes = [1, 2]\n",
    "if len(comp_axes) == 2:\n",
    "    X = np.stack((coeffs[:, comp_axes[0]], coeffs[:, comp_axes[1]]), axis=1)\n",
    "    print(X.shape)\n",
    "    \n",
    "elif len(comp_axes) == 3:\n",
    "    X = np.stack((coeffs[:, comp_axes[0]], coeffs[:, comp_axes[1]], coeffs[:, comp_axes[2]]), axis=1)\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTICS (density-based clustering)\n",
    "# You can adjust the hyperparameters using the interative widgets\n",
    "# The figure will be opened in a new window\n",
    "# please visit the below link for detailed information on OPTICS\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html?highlight=optics#sklearn.cluster.OPTICS\n",
    "\n",
    "%matplotlib qt\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "G = gridspec.GridSpec(2, 4)\n",
    "ax1 = plt.subplot(G[0, :])\n",
    "\n",
    "if X.shape[1] == 3:\n",
    "    ax2 = plt.subplot(G[1, :2], projection=\"3d\")\n",
    "    \n",
    "elif X.shape[1] == 2:\n",
    "    ax2 = plt.subplot(G[1, :2])\n",
    "\n",
    "ax3 = plt.subplot(G[1, 2:])\n",
    "\n",
    "optics_before = [-1, -1, -1]\n",
    "optics_object = []\n",
    "label_result = {\"label_0\":[]}\n",
    "\n",
    "def clustering(msample, steep, msize, img_sel):\n",
    "    start = time.time()\n",
    "    if msample <= 0:\n",
    "        print(\"'min_sample' must be larger than 0\")\n",
    "        return\n",
    "    \n",
    "    if steep <= 0:\n",
    "        print(\"'steepness' must be larger than 0\")\n",
    "        return\n",
    "    \n",
    "    if msize <= 0:\n",
    "        print(\"'min_cluster_size' must be larger than 0\")\n",
    "        return\n",
    "    \n",
    "    optics_check = [msample, steep, msize]\n",
    "\n",
    "    if optics_before != optics_check:\n",
    "        ax1.cla()\n",
    "        del label_result[\"label_0\"]\n",
    "        del optics_object[:]\n",
    "        print(\"optics activated\")\n",
    "        clust = OPTICS(min_samples=msample, xi=steep, min_cluster_size=msize).fit(X)\n",
    "        optics_object.append(clust)\n",
    "        space = np.arange(len(X))\n",
    "        reachability = clust.reachability_[clust.ordering_]\n",
    "        labels = clust.labels_[clust.ordering_]\n",
    "        labels_0 = clust.labels_\n",
    "        label_result[\"label_0\"] = labels_0\n",
    "\n",
    "        for klass, color in zip(range(0, len(color_rep)), color_rep[1:]):\n",
    "            Xk = space[labels == klass]\n",
    "            Rk = reachability[labels == klass]\n",
    "            ax1.plot(Xk, Rk, color, alpha=0.3)\n",
    "        \n",
    "        ax1.plot(space[labels == -1], reachability[labels == -1], \"k.\", alpha=0.3)\n",
    "        ax1.set_ylabel('Reachability-distance')\n",
    "        ax1.set_title('Reachability-Plot')\n",
    "        ax1.grid()\n",
    "        \n",
    "        ax2.cla()\n",
    "        if X.shape[1] == 3:\n",
    "            for klass, color in zip(range(0, len(color_rep)), color_rep[1:]):\n",
    "                Xo = X[labels_0 == klass]\n",
    "                ax2.scatter(Xo[:, 0], Xo[:, 1], Xo[:, 2], color=color, alpha=0.3, marker='.')\n",
    "            ax2.plot(X[labels_0 == -1, 0], X[labels_0 == -1, 1], X[labels_0 == -1, 2], 'k+', alpha=0.1)\n",
    "            ax2.set_title('Automatic Clustering\\nOPTICS(# of clusters=%d)\\n(%f, %f, %f)'%(len(np.unique(labels_0)), msample, steep, msize))\n",
    "\n",
    "        elif X.shape[1] == 2:\n",
    "            for klass, color in zip(range(0, len(color_rep)), color_rep[1:]):\n",
    "                Xo = X[labels_0 == klass]\n",
    "                ax2.scatter(Xo[:, 0], Xo[:, 1], color=color, alpha=0.3, marker='.')\n",
    "            ax2.plot(X[labels_0 == -1, 0], X[labels_0 == -1, 1], 'k+', alpha=0.1)\n",
    "            ax2.set_title('Automatic Clustering\\nOPTICS(# of clusters=%d)\\n(%f, %f, %f)'%(len(np.unique(labels_0)), msample, steep, msize))\n",
    "        \n",
    "\n",
    "    ax3.cla()\n",
    "    \n",
    "    label_reshape_0, _, _ = label_arrangement(label_result[\"label_0\"], data_shape_new)\n",
    "    \n",
    "    ax3.imshow(label_reshape_0[img_sel-1], cmap=custom_cmap, norm=norm)\n",
    "    ax3.set_title(\"image %d\"%(img_sel), fontsize=10)\n",
    "    ax3.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    del optics_before[:]\n",
    "    for i in range(len(optics_check)):\n",
    "        optics_before.append(optics_check[i])\n",
    "    print(\"minimum number of samples in a neighborhood: %f\"%msample)\n",
    "    print(\"minimum steepness: %f\"%steep)\n",
    "    print(\"minumum number of samples in a cluster: %f\"%msize)\n",
    "    print(\"%.2f min have passed\"%((time.time()-start)/60))\n",
    "\n",
    "\n",
    "st = {\"description_width\": \"initial\"}\n",
    "msample_wg = pyw.FloatText(value=0.05, description=\"min. # of samples in a neighborhood\", style=st)\n",
    "steep_wg = pyw.FloatText(value=0.001, description=\"min. steepness\", style=st)\n",
    "msize_wg = pyw.FloatText(value=0.05, description=\"min. # of samples in a cluster\", style=st)\n",
    "img_wg = pyw.Select(options=np.arange(num_img)+1, value=1, description=\"image selection\", style=st)\n",
    "\n",
    "pyw.interact(clustering, msample=msample_wg, steep=steep_wg, msize=msize_wg,  img_sel=img_wg)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spatial distribution and representative spectra of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the clustering result\n",
    "label_selected = label_result[\"label_0\"].copy()\n",
    "label_sort = np.unique(label_selected)\n",
    "label_reshape, selected, hist = label_arrangement(label_selected, data_shape_new)\n",
    "num_label = len(label_sort)\n",
    "print(label_sort) # label \"-1\" -> not a cluster\n",
    "print(hist) # number of data points in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering result - clusters in the final DR space\n",
    "# black points -> label \"-1\"\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "for klass, color in zip(range(0, len(color_rep)), color_rep[1:]):\n",
    "    Xo = X[label_selected == klass]\n",
    "    ax.scatter(Xo[:, 0], Xo[:, 1], color=color, alpha=0.3, marker='.')\n",
    "ax.plot(X[label_selected == -1, 0], X[label_selected == -1, 1], 'k+', alpha=0.1)\n",
    "#ax.axis(\"off\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering result - spatial distribution of each cluster\n",
    "row_n = 1\n",
    "col_n = num_img\n",
    "    \n",
    "fig, ax = plt.subplots(row_n, col_n, figsize=(7, 10))\n",
    "if num_img != 1:\n",
    "    for i, axs in enumerate(ax.flat):\n",
    "        axs.imshow(label_reshape[i], cmap=custom_cmap, norm=norm)\n",
    "        axs.set_title(\"image %d\"%(i+1), fontsize=10)\n",
    "        axs.axis(\"off\")\n",
    "\n",
    "else:\n",
    "    ax.imshow(label_reshape[0], cmap=custom_cmap, norm=norm)\n",
    "    ax.set_title(\"image %d\"%(1), fontsize=10)\n",
    "    ax.axis(\"off\")\n",
    "#fig.colorbar(sm)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the spatial distribution as a tiff stack\n",
    "save_result = label_reshape[0].copy()\n",
    "save_result = save_result[:, :, np.newaxis]\n",
    "save_result = save_result.astype(np.int16)\n",
    "print(save_result.shape)\n",
    "\n",
    "tifffile.imsave(tkf.asksaveasfilename(), save_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering result\n",
    "if num_img != 1:\n",
    "    for i in range(num_label):\n",
    "        fig, ax = plt.subplots(1, num_img, figsize=(7*num_img, 7))\n",
    "        for j in range(num_img):\n",
    "            ax[j].imshow(selected[i][j], cmap=\"afmhot\")\n",
    "            ax[j].set_title(\"label %d map\"%(label_sort[i]+1), fontsize=10)\n",
    "            ax[j].axis(\"off\")\n",
    "            fig.tight_layout()\n",
    "        plt.show()\n",
    "else:            \n",
    "    for i in range(num_label):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7*num_img, 7))\n",
    "        tmp = ax.imshow(selected[i][0], cmap=\"afmhot\")\n",
    "        ax.axis(\"off\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering result - representative spectra (cropped)\n",
    "# average all of the spectra in each cluster\n",
    "lines = np.zeros((num_label, depth))\n",
    "\n",
    "for i in range(num_label):\n",
    "    ind = np.where(label_selected == label_sort[i])\n",
    "    print(\"number of pixels in the label %d cluster: %d\"%(label_sort[i], hist[i]))\n",
    "    lines[i] = np.mean(dataset_flat[ind], axis=0)\n",
    "    \n",
    "fig, ax = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "# normalize representative spectra for comparison\n",
    "denominator = np.max(lines[:, :20], axis=1)\n",
    "lines = lines / denominator[:, np.newaxis]\n",
    "\n",
    "if -1 in label_sort:\n",
    "    for i in range(1, num_label):\n",
    "        ax[0][0].plot(e_range, (lines[i]), label=\"cluster %d\"%(i), c=color_rep[i])\n",
    "        ax[1][0].plot(e_range, (lines[i]+(i-1)*0.1), label=\"cluster %d\"%(i), c=color_rep[i])\n",
    "        \n",
    "else:\n",
    "    for i in range(0, num_label):\n",
    "        ax[0][0].plot(e_range, (lines[i]), label=\"cluster %d\"%(i+1), c=color_rep[i+1])\n",
    "        ax[1][0].plot(e_range, (lines[i]+i*0.1), label=\"cluster %d\"%(i+1), c=color_rep[i+1])\n",
    "\n",
    "ax[0][0].grid()\n",
    "ax[0][0].legend(fontsize=\"x-large\")\n",
    "ax[0][0].set_xlabel(\"eV\")\n",
    "ax[1][0].grid()\n",
    "ax[1][0].legend(fontsize=\"x-large\")\n",
    "ax[1][0].set_xlabel(\"eV\")\n",
    "\n",
    "# clustering result - representative spectra (original)\n",
    "# average all of the spectra in each cluster\n",
    "lines_original = np.zeros((num_label, depth_original))\n",
    "\n",
    "for i in range(num_label):\n",
    "    ind = np.where(label_selected == label_sort[i])\n",
    "    #print(\"number of pixels in the label %d cluster: %d\"%(label_sort[i], hist[i]))\n",
    "    lines_original[i] = np.mean(dataset_original_flat[ind], axis=0)\n",
    "\n",
    "# normalize representative spectra for comparison\n",
    "denominator = np.max(lines_original[:, :20], axis=1)\n",
    "lines_original = lines_original / denominator[:, np.newaxis]\n",
    "\n",
    "\n",
    "if -1 in label_sort:\n",
    "    for i in range(1, num_label):\n",
    "        ax[0][1].plot(e_range_original, (lines_original[i]), label=\"cluster %d\"%(i), c=color_rep[i])\n",
    "        ax[1][1].plot(e_range_original, (lines_original[i]+(i-1)*0.1), label=\"cluster %d\"%(i), c=color_rep[i])\n",
    "        \n",
    "else:\n",
    "    for i in range(0, num_label):\n",
    "        ax[0][1].plot(e_range_original, (lines_original[i]), label=\"cluster %d\"%(i+1), c=color_rep[i+1])\n",
    "        ax[1][1].plot(e_range_original, (lines_original[i]+i*0.1), label=\"cluster %d\"%(i+1), c=color_rep[i+1])\n",
    "\n",
    "ax[0][1].grid()\n",
    "ax[0][1].legend(fontsize=\"x-large\")\n",
    "ax[0][1].set_xlabel(\"eV\")\n",
    "ax[1][1].grid()\n",
    "ax[1][1].legend(fontsize=\"x-large\")\n",
    "ax[1][1].set_xlabel(\"eV\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the representative spectra as a tiff stack\n",
    "tifffile.imsave(tkf.asksaveasfilename(), lines.reshape(lines.shape[0], -1, lines.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"%d gpu available\"%(torch.cuda.device_count()))\n",
    "    cuda_device = torch.device(\"cuda:0\")\n",
    "    print(torch.cuda.get_device_name(cuda_device))\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "else:\n",
    "    cuda_device = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_list = np.arange(1, len(lines))\n",
    "cluster_list = [4]\n",
    "ref_spec = []\n",
    "for i in cluster_list:\n",
    "    ref_spec.append(lines[i])\n",
    "\n",
    "ref_spec = np.asarray(ref_spec)\n",
    "ref_spec = torch.from_numpy(ref_spec).to(torch.float32)\n",
    "ref_spec = ref_spec.cuda(cuda_device)\n",
    "ref_spec.requires_grad_(requires_grad=False)\n",
    "print(ref_spec.device)\n",
    "print(ref_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1600\n",
    "mini_batches = [dataset_input[k:k+batch_size] for k in range(0, len(dataset_input), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_tmp = torch.randn((batch_size, ref_spec.shape[0])).to(torch.float32)\n",
    "coeff_tmp = coeff_tmp.cuda(cuda_device)\n",
    "coeff_tmp.requires_grad_(requires_grad=True)\n",
    "print(coeff_tmp.device)\n",
    "print(coeff_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rate = 0.05\n",
    "moment = 0.00\n",
    "optimizer = optim.SGD([coeff_tmp], lr=l_rate, momentum=moment)\n",
    "n_iter = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_ret_tmp = []\n",
    "for i, m_batch in enumerate(mini_batches):\n",
    "    nn.init.xavier_uniform_(coeff_tmp)\n",
    "    batch = torch.from_numpy(m_batch).to(torch.float32).cuda(cuda_device)\n",
    "    for n in range(n_iter):\n",
    "        reconstructed_tmp = torch.matmul(coeff_tmp, ref_spec)\n",
    "        loss = LA.norm((batch - reconstructed_tmp), 2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        coeff_tmp.data.clamp_(min=0.0)\n",
    "        \n",
    "    coeff_ret_tmp.extend(coeff_tmp.data.cpu().numpy().tolist())\n",
    "    if int((i+1) % 4) == 0:\n",
    "        print(\"%d-th batch of %d batches completed\"%(i+1, len(mini_batches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_ret_tmp = np.asarray(coeff_ret_tmp)\n",
    "coeff_ret = np.zeros_like(coeff_ret_tmp)\n",
    "coeff_ret[ri] = coeff_ret_tmp.copy()\n",
    "coeff_ret_reshape = reshape_coeff(coeff_ret, data_shape_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the coefficient maps\n",
    "if num_img != 1:\n",
    "    for i in range(len(cluster_list)):\n",
    "        fig, ax = plt.subplots(1, num_img, figsize=(7*num_img, 7))\n",
    "        for j in range(num_img):\n",
    "            tmp = ax[j].imshow(coeff_ret_reshape[j][:, :, i], cmap=\"afmhot\")\n",
    "            ax[j].set_title(\"representative spectrum %d map\"%(i+1), fontsize=10)\n",
    "            ax[j].axis(\"off\")\n",
    "            fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()\n",
    "else:            \n",
    "    for i in range(len(cluster_list)):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7, 7*num_img))\n",
    "        tmp = ax.imshow(coeff_ret_reshape[0][:, :, i], cmap=\"afmhot\")\n",
    "        ax.set_title(\"representative spectrum %d map\"%(i+1), fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "        fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
