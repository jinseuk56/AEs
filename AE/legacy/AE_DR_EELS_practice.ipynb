{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import ipywidgets as pyw\n",
    "import hyperspy.api as hys\n",
    "import tkinter.filedialog as tkf\n",
    "from tabulate import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import linalg as LA\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a customized colorbar\n",
    "color_rep = [\"black\", \"red\", \"green\", \"blue\", \"orange\", \"purple\", \"yellow\", \"lime\", \n",
    "             \"cyan\", \"magenta\", \"lightgray\", \"peru\", \"springgreen\", \"deepskyblue\", \n",
    "             \"hotpink\", \"darkgray\"]\n",
    "print(len(color_rep))\n",
    "custom_cmap = mcolors.ListedColormap(color_rep)\n",
    "bounds = np.arange(-1, len(color_rep))\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=len(color_rep))\n",
    "sm = cm.ScalarMappable(cmap=custom_cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "cm_rep = [\"gray\", \"Reds\", \"Greens\", \"Blues\", \"Oranges\", \"Purples\"]\n",
    "print(len(cm_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_one_rescale(spectrum):\n",
    "    \"\"\"\n",
    "    normalize one spectrum from 0.0 to 1.0\n",
    "    \"\"\"\n",
    "    spectrum = spectrum.clip(min=0.0)\n",
    "    min_val = np.min(spectrum)\n",
    "    \n",
    "    rescaled = spectrum - min_val\n",
    "    \n",
    "    if np.max(rescaled) != 0:\n",
    "        rescaled = rescaled / np.max(rescaled)\n",
    "    \n",
    "    return rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threed_roll_axis(img):\n",
    "    stack = np.rollaxis(img, 2, 0)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(adr, rescale=False, crop=None, roll_axis=False):\n",
    "    \"\"\"\n",
    "    load a spectrum image\n",
    "    \"\"\"\n",
    "    storage = []\n",
    "    shape = []\n",
    "    for i, adr in enumerate(adr):\n",
    "        if crop:\n",
    "            temp = hys.load(adr)\n",
    "            print(temp.axes_manager[2])\n",
    "            temp = temp.isig[crop[0]:crop[1]]\n",
    "            temp = temp.data\n",
    "            print(temp.shape)\n",
    "        \n",
    "        else:\n",
    "            temp = hys.load(adr).data\n",
    "            if roll_axis:\n",
    "                temp = threed_roll_axis(temp)\n",
    "            print(temp.shape)\n",
    "            \n",
    "        if rescale:\n",
    "            for j in range(temp.shape[0]):\n",
    "                for k in range(temp.shape[1]):\n",
    "                    temp[j, k] = zero_one_rescale(temp[j, k])\n",
    "        shape.append(temp.shape)\n",
    "        storage.append(temp)\n",
    "    \n",
    "    shape = np.asarray(shape)\n",
    "    return storage, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning_SI(si, bin_y, bin_x, str_y, str_x, offset, depth, rescale=True):\n",
    "    \"\"\"\n",
    "    re-bin a spectrum image\n",
    "    \"\"\"\n",
    "    si = np.asarray(si)\n",
    "    rows = range(0, si.shape[0]-bin_y+1, str_y)\n",
    "    cols = range(0, si.shape[1]-bin_x+1, str_x)\n",
    "    new_shape = (len(rows), len(cols))\n",
    "    \n",
    "    binned = []\n",
    "    for i in rows:\n",
    "        for j in cols:\n",
    "            temp_sum = np.mean(si[i:i+bin_y, j:j+bin_x, offset:(offset+depth)], axis=(0, 1))\n",
    "            if rescale:\n",
    "                binned.append(zero_one_rescale(temp_sum))\n",
    "            else:\n",
    "                binned.append(temp_sum)\n",
    "            \n",
    "    binned = np.asarray(binned).reshape(new_shape[0], new_shape[1], depth)\n",
    "    \n",
    "    return binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_coeff(coeffs, new_shape):\n",
    "    \"\"\"\n",
    "    reshape a coefficient matrix to restore the original scanning shapes.\n",
    "    \"\"\"\n",
    "    coeff_reshape = []\n",
    "    for i in range(len(new_shape)):\n",
    "        temp = coeffs[:int(new_shape[i, 0]*new_shape[i, 1]), :]\n",
    "        coeffs = np.delete(coeffs, range(int(new_shape[i, 0]*new_shape[i, 1])), axis=0)\n",
    "        temp = np.reshape(temp, (new_shape[i, 0], new_shape[i, 1], -1))\n",
    "        #print(temp.shape)\n",
    "        coeff_reshape.append(temp)\n",
    "        \n",
    "    return coeff_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_adr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_adr.extend(tkf.askopenfilenames())\n",
    "print(len(file_adr))\n",
    "print(*file_adr, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_img = len(file_adr)\n",
    "print(num_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spectrum images\n",
    "cr_range = [0.5, 10.0, 0.01] # reference\n",
    "data_original, shape_original = data_load(file_adr, rescale=False, crop=cr_range, roll_axis=False)\n",
    "print(len(data_original))\n",
    "print(shape_original)\n",
    "\n",
    "e_range_original = np.arange(cr_range[0], cr_range[1], cr_range[2])\n",
    "print(len(e_range_original))\n",
    "\n",
    "# load spectrum images\n",
    "cr_range = [1.0, 3.0, 0.01] # actual input\n",
    "data_storage, data_shape = data_load(file_adr, rescale=False, crop=cr_range, roll_axis=False)\n",
    "print(len(data_storage))\n",
    "print(data_shape)\n",
    "\n",
    "e_range = np.arange(cr_range[0], cr_range[1], cr_range[2])\n",
    "print(len(e_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-bin spectrum images in order to mitigate noises\n",
    "bin_y = 1 # binning size (height)\n",
    "bin_x = 1 # binning size (width)\n",
    "str_y = 1 # stride width-direction\n",
    "str_x = 1 # stride height-direction\n",
    "\n",
    "# reference\n",
    "dataset_original = []\n",
    "shape_new_original = []\n",
    "\n",
    "offset = 0\n",
    "depth_original = len(e_range_original)\n",
    "for img in data_original:\n",
    "    print(img.shape)\n",
    "    processed = binning_SI(img, bin_y, bin_x, str_y, str_x, offset, depth_original, rescale=False)\n",
    "    print(processed.shape)\n",
    "    shape_new_original.append(processed.shape)\n",
    "    dataset_original.append(processed)\n",
    "    \n",
    "shape_new_original = np.asarray(shape_new_original)\n",
    "print(shape_new_original)\n",
    "\n",
    "# actual input\n",
    "dataset = []\n",
    "data_shape_new = []\n",
    "offset = 0\n",
    "depth = len(e_range)\n",
    "for img in data_storage:\n",
    "    print(img.shape)\n",
    "    processed = binning_SI(img, bin_y, bin_x, str_y, str_x, offset, depth, rescale=True) # include the step for re-scaling the actual input\n",
    "    print(processed.shape)\n",
    "    data_shape_new.append(processed.shape)\n",
    "    dataset.append(processed)\n",
    "    \n",
    "data_shape_new = np.asarray(data_shape_new)\n",
    "print(data_shape_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_original_flat = []\n",
    "for i in range(num_img):\n",
    "    dataset_original_flat.extend(dataset_original[i].clip(min=0.0).reshape(-1, depth_original).tolist())\n",
    "    \n",
    "dataset_original_flat = np.asarray(dataset_original_flat)\n",
    "print(dataset_original_flat.shape)\n",
    "\n",
    "# create the input dataset\n",
    "dataset_flat = []\n",
    "for i in range(num_img):\n",
    "    dataset_flat.extend(dataset[i].clip(min=0.0).reshape(-1, depth).tolist())\n",
    "    \n",
    "dataset_flat = np.asarray(dataset_flat)\n",
    "print(dataset_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = len(dataset_flat)\n",
    "ri = np.random.choice(total_num, total_num, replace=False)\n",
    "\n",
    "dataset_input = dataset_flat[ri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_ae(nn.Module):\n",
    "    def __init__(self, input_size, encoded_dimension):\n",
    "        super(linear_ae, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.reduction = encoded_dimension\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.input_size, self.reduction, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.reduction, self.input_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"%d gpu available\"%(torch.cuda.device_count()))\n",
    "    cuda_device = torch.device(\"cuda:0\")\n",
    "    print(torch.cuda.get_device_name(cuda_device))\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "else:\n",
    "    cuda_device = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comp = 5\n",
    "model = linear_ae(depth, num_comp)\n",
    "model.cuda(cuda_device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1600\n",
    "mini_batches = [dataset_input[k:k+batch_size] for k in range(0, len(dataset_input), batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 1000\n",
    "l_rate = 0.01\n",
    "lmbd_main = 1.0\n",
    "lmbd_tv = 0.001\n",
    "lmbd_reg = 0\n",
    "alpha = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=l_rate)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "nn.init.xavier_uniform_(model.encoder[0].weight)\n",
    "torch.nn.init.orthogonal_(model.decoder[0].weight)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-pencil",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ae_coeffs = []\n",
    "ae_bias = []\n",
    "for epoch in range(n_epoch):\n",
    "    for i, m_batch in enumerate(mini_batches):\n",
    "        \n",
    "        x = torch.from_numpy(mini_batches[i])\n",
    "        x = x.to(torch.float32)\n",
    "        x = x.to(cuda_device)\n",
    "        x.requires_grad_(requires_grad=False)\n",
    "        \n",
    "        encoded, decoded = model(x)\n",
    "        \n",
    "        l1_reg = 0\n",
    "        l2_reg = 0\n",
    "        tv_reg = 0\n",
    "\n",
    "        for i in range(num_comp):\n",
    "            tv_reg += lmbd_tv*LA.norm(torch.gradient(model.decoder[0].weight[:, i])[0], 1)\n",
    "            l1_reg += lmbd_reg*alpha*(LA.norm(model.decoder[0].weight[:, i], 1))#+LA.norm(encoded.flatten(), 1))\n",
    "            l2_reg += lmbd_reg*(1-alpha)*(LA.norm(model.decoder[0].weight[:, i], 2))#+LA.norm(encoded.flatten(), 2))\n",
    "        \n",
    "        main_loss = lmbd_main * LA.norm((decoded - x), 2) / len(m_batch)\n",
    "        total_loss = main_loss + l1_reg + l2_reg + tv_reg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.decoder[0].weight.data.clamp_(min=0.0)\n",
    "        \n",
    "        if epoch == n_epoch-1:\n",
    "            coeff_batch = encoded.data.cpu().numpy().tolist()\n",
    "            ae_coeffs.extend(coeff_batch)            \n",
    "    \n",
    "    \n",
    "    if epoch == 0:\n",
    "        print(torch.cuda.memory_summary(device=cuda_device))\n",
    "    \n",
    "    if (epoch+1) % int(n_epoch/10) == 0:\n",
    "        print(tabulate([\n",
    "                        [\"epoch\", epoch+1], \n",
    "                        [\"total loss\", total_loss.item()],\n",
    "                        [\"-main loss\", main_loss.item(), main_loss.item()*100/total_loss.item()],\n",
    "                        [\"-L1 reg.\", l1_reg.item(), l1_reg.item()*100/total_loss.item()],\n",
    "                        [\"-L2 reg.\", l2_reg.item(), l2_reg.item()*100/total_loss.item()],\n",
    "                        [\"-TV reg.\", tv_reg.item(), tv_reg.item()*100/total_loss.item()],\n",
    "                        ]))\n",
    "        print(\"%.2f minutes have passed\"%((time.time()-start)/60))\n",
    "        \n",
    "        fig, ax = plt.subplots(1, num_comp, figsize=(5*num_comp, 5))\n",
    "        for i in range(num_comp):\n",
    "            ax[i].plot(e_range, model.decoder[0].weight.data.cpu()[:, i])\n",
    "            ax[i].grid()\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"The training has been finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_coeffs = np.asarray(ae_coeffs)\n",
    "ae_comp_vectors = model.decoder[0].weight.data.cpu().numpy().T\n",
    "print(ae_coeffs.shape)\n",
    "print(ae_comp_vectors.shape)\n",
    "\n",
    "# convert the coefficient matrix into coefficient maps\n",
    "coeffs = np.zeros_like(ae_coeffs)\n",
    "coeffs[ri] = ae_coeffs.copy()\n",
    "coeffs_reshape = reshape_coeff(coeffs, data_shape_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize loading vectors\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4)) # all loading vectors\n",
    "for i in range(num_comp):\n",
    "    ax[0].plot(e_range, ae_comp_vectors[i], \"-\", c=color_rep[i+1], label=\"loading vector %d\"%(i+1))\n",
    "ax[0].grid()\n",
    "ax[0].legend(fontsize=\"large\")\n",
    "ax[0].set_xlabel(\"eV\", fontsize=10)\n",
    "ax[0].tick_params(axis=\"x\", labelsize=10)\n",
    "#ax[0].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "sel_nmf_comp = [2, 3, 4, 5] # choose several loading vectors to visualize\n",
    "for i in sel_nmf_comp:\n",
    "    ax[1].plot(e_range, ae_comp_vectors[i-1], \"-\", c=color_rep[i], label=\"loading vector %d\"%(i))\n",
    "ax[1].grid()\n",
    "ax[1].legend(fontsize=\"large\")\n",
    "ax[1].set_xlabel(\"eV\", fontsize=10)\n",
    "ax[1].tick_params(axis=\"x\", labelsize=10)\n",
    "#ax[1].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-crime",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize coefficient maps\n",
    "\n",
    "if num_img != 1:\n",
    "    for i in range(num_comp):\n",
    "        fig, ax = plt.subplots(1, num_img, figsize=(5, 5))\n",
    "        for j in range(num_img):\n",
    "            tmp = ax[j].imshow(coeffs_reshape[j][:, :, i], \n",
    "                               vmin=np.percentile(coeffs_reshape[j][:, :, i], 50), cmap=\"afmhot\")\n",
    "            ax[j].set_title(\"loading vector %d map\"%(i+1), fontsize=10)\n",
    "            ax[j].axis(\"off\")\n",
    "            \n",
    "else:\n",
    "    for i in range(num_comp):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "        tmp = ax.imshow(coeffs_reshape[0][:, :, i], \n",
    "                        vmin=np.percentile(coeffs_reshape[0][:, :, i], 50), cmap=\"afmhot\")\n",
    "        ax.set_title(\"loading vector %d map\"%(i+1), fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "        fig.tight_layout()\n",
    "        fig.colorbar(tmp, cax=fig.add_axes([0.88, 0.15, 0.04, 0.7]))\n",
    "        plt.show()\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D subspace\n",
    "%matplotlib qt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "\n",
    "def projection(c1, c2):\n",
    "    ax.cla()\n",
    "    ax.scatter(coeffs[:, c1], coeffs[:, c2], s=30, c=\"black\", alpha=0.5)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"loading vector %d\"%(c1+1), fontsize=15)\n",
    "    ax.set_ylabel(\"loading vector %d\"%(c2+1), fontsize=15)\n",
    "    ax.tick_params(axis=\"both\", labelsize=15)\n",
    "    fig.canvas.draw()\n",
    "    fig.tight_layout()\n",
    "\n",
    "x_widget = pyw.IntSlider(min=0, max=num_comp-1, step=1, value=0)\n",
    "y_widget = pyw.IntSlider(min=0, max=num_comp-1, step=1, value=1)\n",
    "\n",
    "pyw.interact(projection, c1=x_widget, c2=y_widget)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
