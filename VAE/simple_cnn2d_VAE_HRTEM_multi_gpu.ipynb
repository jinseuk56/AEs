{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f743f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import ipywidgets as pyw\n",
    "import tkinter.filedialog as tkf\n",
    "import tifffile\n",
    "from tabulate import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import linalg as LA\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054febda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a customized colorbar\n",
    "color_rep = [\"black\", \"red\", \"green\", \"blue\", \"orange\", \"purple\", \"yellow\", \"lime\", \n",
    "             \"cyan\", \"magenta\", \"lightgray\", \"peru\", \"springgreen\", \"deepskyblue\", \n",
    "             \"hotpink\", \"darkgray\"]\n",
    "print(len(color_rep))\n",
    "custom_cmap = mcolors.ListedColormap(color_rep)\n",
    "bounds = np.arange(-1, len(color_rep))\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=len(color_rep))\n",
    "sm = cm.ScalarMappable(cmap=custom_cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "cm_rep = [\"gray\", \"Reds\", \"Greens\", \"Blues\", \"Oranges\", \"Purples\"]\n",
    "print(len(cm_rep))\n",
    "\n",
    "def zero_one_rescale(spectrum):\n",
    "    \"\"\"\n",
    "    normalize one spectrum from 0.0 to 1.0\n",
    "    \"\"\"\n",
    "    spectrum = spectrum.clip(min=0.0)\n",
    "    min_val = np.min(spectrum)\n",
    "    \n",
    "    rescaled = spectrum - min_val\n",
    "    \n",
    "    if np.max(rescaled) != 0:\n",
    "        rescaled = rescaled / np.max(rescaled)\n",
    "    \n",
    "    return rescaled\n",
    "\n",
    "def fourd_roll_axis(stack):\n",
    "    stack = np.rollaxis(np.rollaxis(stack, 2, 0), 3, 1)\n",
    "    return stack\n",
    "\n",
    "def reshape_coeff(coeffs, new_shape):\n",
    "    \"\"\"\n",
    "    reshape a coefficient matrix to restore the original scanning shapes.\n",
    "    \"\"\"\n",
    "    coeff_reshape = []\n",
    "    for i in range(len(new_shape)):\n",
    "        temp = coeffs[:int(new_shape[i, 0]*new_shape[i, 1]), :]\n",
    "        coeffs = np.delete(coeffs, range(int(new_shape[i, 0]*new_shape[i, 1])), axis=0)\n",
    "        temp = np.reshape(temp, (new_shape[i, 0], new_shape[i, 1], -1))\n",
    "        #print(temp.shape)\n",
    "        coeff_reshape.append(temp)\n",
    "        \n",
    "    return coeff_reshape\n",
    "\n",
    "def radial_indices(shape, radial_range, center=None):\n",
    "    y, x = np.indices(shape)\n",
    "    if not center:\n",
    "        center = np.array([(y.max()-y.min())/2.0, (x.max()-x.min())/2.0])\n",
    "    \n",
    "    r = np.hypot(y - center[0], x - center[1])\n",
    "    ri = np.ones(r.shape)\n",
    "    \n",
    "    if len(np.unique(radial_range)) > 1:\n",
    "        ri[np.where(r <= radial_range[0])] = 0\n",
    "        ri[np.where(r > radial_range[1])] = 0\n",
    "        \n",
    "    else:\n",
    "        r = np.round(r)\n",
    "        ri[np.where(r != round(radial_range[0]))] = 0\n",
    "    \n",
    "    return ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08c505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split = 2\n",
    "n_each_split = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f889d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_adr = []\n",
    "for i in range(n_split):\n",
    "    directory_path = tkf.askdirectory()\n",
    "    split_adr.append(glob.glob(directory_path+\"/*\"))\n",
    "print(len(split_adr))\n",
    "split_adr = np.asarray(split_adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_adr = []\n",
    "for i in range(n_split):\n",
    "    ri = np.random.choice(len(split_adr[i]), n_each_split, replace=False)\n",
    "    file_adr.extend(split_adr[i, ri].tolist())\n",
    "print(len(file_adr))\n",
    "print(*file_adr, sep=\"/n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75714b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_img = len(file_adr)\n",
    "print(num_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = []\n",
    "data_shape = []\n",
    "for i in range(num_img):\n",
    "    tmp = tifffile.imread(file_adr[i])\n",
    "    #tmp = hys.load(file_adr[i]).data\n",
    "    #tmp = fourd_roll_axis(tmp)\n",
    "    print(tmp.shape)\n",
    "    data_shape.append(list(tmp.shape[:2]))\n",
    "    data_original.append(tmp)\n",
    "    \n",
    "data_shape = np.asarray(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d445dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_size = data_original[0].shape[2]\n",
    "print(w_size)\n",
    "\n",
    "dataset_flat = []\n",
    "for i in range(num_img):\n",
    "    dataset_flat.extend(data_original[i].reshape(-1, w_size, w_size).tolist())\n",
    "    \n",
    "dataset_flat = np.asarray(dataset_flat)\n",
    "dataset_flat = dataset_flat / np.max(dataset_flat, axis=(1, 2))[:, np.newaxis, np.newaxis]\n",
    "print(dataset_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e22541",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = len(dataset_flat)\n",
    "ri = np.random.choice(total_num, total_num, replace=False)\n",
    "\n",
    "dataset_input = dataset_flat[ri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_VAE(nn.Module):\n",
    "    def __init__(self, in_dim, final_length, channels, kernels, strides, paddings, z_dim, \n",
    "                 dec_kernels, dec_strides, dec_paddings, dec_outpads, f_kernel):\n",
    "        super(simple_VAE, self).__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.final_length = final_length\n",
    "        self.channels = channels\n",
    "        \n",
    "        enc_net = []\n",
    "        enc_net.append(nn.Conv2d(1, channels[0], kernels[0], stride=strides[0], \n",
    "                                 padding=paddings[0], bias=True))\n",
    "        enc_net.append(nn.BatchNorm2d(channels[0]))\n",
    "        enc_net.append(nn.LeakyReLU(0.1))\n",
    "        for i in range(1, len(channels)):\n",
    "            enc_net.append(nn.Conv2d(channels[i-1], channels[i], kernels[i], stride=strides[i],\n",
    "                                     padding=paddings[i], bias=True))\n",
    "            enc_net.append(nn.BatchNorm2d(channels[i]))\n",
    "            enc_net.append(nn.LeakyReLU(0.1))\n",
    "            \n",
    "        enc_net.append(nn.Flatten())\n",
    "        enc_net.append(nn.Linear(self.final_length**2*channels[-1], 2*self.z_dim))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*enc_net)\n",
    "        \n",
    "        self.init_decoder = nn.Linear(self.z_dim, self.final_length**2*channels[-1])\n",
    "        \n",
    "        dec_net = []\n",
    "        for i in range(len(channels)-1, 0, -1):\n",
    "            dec_net.append(nn.ConvTranspose2d(channels[i], channels[i-1], dec_kernels[i], dec_strides[i],\n",
    "                                              dec_paddings[i], output_padding=dec_outpad[i], bias=True))\n",
    "            dec_net.append(nn.BatchNorm2d(channels[i-1]))\n",
    "            dec_net.append(nn.LeakyReLU(0.1))\n",
    "            \n",
    "        dec_net.append(nn.ConvTranspose2d(channels[0], 1, dec_kernels[0], dec_strides[0], \n",
    "                                          dec_paddings[0], output_padding=dec_outpad[0], bias=True))\n",
    "        dec_net.append(nn.BatchNorm2d(1))\n",
    "        dec_net.append(nn.LeakyReLU(0.1))\n",
    "        \n",
    "        dec_net.append(nn.Conv2d(1, 1, f_kernel, bias=True))\n",
    "        dec_net.append(nn.Sigmoid())\n",
    "        \n",
    "        self.decoder = nn.Sequential(*dec_net)\n",
    "        \n",
    "        \n",
    "    def encode(self, x):\n",
    "        \n",
    "        latent = self.encoder(x)\n",
    "        mu = latent[:, :self.z_dim]\n",
    "        logvar = latent[:, self.z_dim:]\n",
    "        \n",
    "        return mu, logvar\n",
    "        \n",
    "                \n",
    "    def reparametrization(self, mu, logvar):\n",
    "        \n",
    "        return mu+torch.exp(0.5*logvar)*torch.randn_like(logvar)\n",
    "        \n",
    "        \n",
    "    def decode(self, z):\n",
    "        \n",
    "        init_decoded = self.init_decoder(z)\n",
    "        init_decoded = init_decoded.view(-1, self.channels[-1], self.final_length, self.final_length)\n",
    "        \n",
    "        return self.decoder(init_decoded)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrization(mu, logvar)\n",
    "        \n",
    "        return mu, logvar, z, self.decode(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"%d gpu available\"%(torch.cuda.device_count()))\n",
    "    cuda_device = torch.device(\"cuda:0\")\n",
    "    print(torch.cuda.get_device_name(cuda_device))\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "else:\n",
    "    cuda_device = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5eed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comp = 2\n",
    "channels = [256, 128, 64, 32]\n",
    "kernels = [10, 10, 10, 10]\n",
    "padding = [1, 1, 1, 1]\n",
    "stride = [2, 2, 2, 2]\n",
    "\n",
    "dat_dim = []\n",
    "tmp_dim = w_size\n",
    "for i in range(len(kernels)):\n",
    "    tmp_dim += (-kernels[i]+2*padding[i])\n",
    "    tmp_dim /= stride[i]\n",
    "    tmp_dim += 1\n",
    "    dat_dim.append(int(tmp_dim))\n",
    "    #dat_dim.append(tmp_dim)\n",
    "\n",
    "print(dat_dim)\n",
    "print(kernels)\n",
    "print(channels)\n",
    "print(padding)\n",
    "print(stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_kernel = [10, 10, 10, 10]\n",
    "dec_stride = [2, 2, 2, 2]\n",
    "dec_padding = [1, 1, 1, 1]\n",
    "dec_outpad = [1, 1, 1, 1]\n",
    "\n",
    "dec_dim = []\n",
    "enc_dim = dat_dim[-1]\n",
    "for i in range(len(dec_kernel)):\n",
    "    enc_dim = (enc_dim-1)*dec_stride[i] + dec_kernel[i] - 2*dec_padding[i] + dec_outpad[i]\n",
    "    dec_dim.append(enc_dim)\n",
    "    \n",
    "print(dec_dim)\n",
    "\n",
    "dec_kernel.reverse()\n",
    "dec_stride.reverse()\n",
    "dec_padding.reverse()\n",
    "dec_outpad.reverse()\n",
    "\n",
    "final_kernel = 10\n",
    "print(dec_dim[-1] - final_kernel + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_VAE(w_size, dat_dim[-1], channels, kernels, stride, padding, num_comp, \n",
    "                   dec_kernel, dec_stride, dec_padding, dec_outpad, final_kernel)\n",
    "model = nn.DataParallel(model)\n",
    "model.cuda(cuda_device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029be140",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "mini_batches = [dataset_input[k:k+batch_size] for k in range(0, len(dataset_input), batch_size)]\n",
    "print(len(mini_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 500\n",
    "l_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=l_rate)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4cf9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "latent_z = []\n",
    "z_mu = []\n",
    "z_logvar = []\n",
    "n_fig = 5\n",
    "for epoch in range(n_epoch):\n",
    "    loss_epoch = 0\n",
    "    recon_loss = 0\n",
    "    KLD_loss = 0\n",
    "    for i, m_batch in enumerate(mini_batches):\n",
    "        \n",
    "        x = torch.from_numpy(mini_batches[i])\n",
    "        x = x.to(torch.float32)\n",
    "        x = x.to(cuda_device)\n",
    "        x.requires_grad_(requires_grad=False)\n",
    "        \n",
    "        mu, logvar, z, x_ = model(x)\n",
    "        \n",
    "        reconstruction_error = F.binary_cross_entropy(x_.squeeze(), x, reduction=\"sum\")\n",
    "        KL_divergence = -0.5*torch.sum(1+logvar-mu**2-logvar.exp())\n",
    "        \n",
    "        loss = reconstruction_error + KL_divergence\n",
    "        loss_epoch += loss.item()\n",
    "        recon_loss += reconstruction_error.item()\n",
    "        KLD_loss += KL_divergence.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == n_epoch-1:\n",
    "            latent_z.extend(z.data.cpu().numpy().tolist())\n",
    "            z_mu.extend(mu.data.cpu().numpy().tolist())\n",
    "            z_logvar.extend(logvar.data.cpu().numpy().tolist())\n",
    "            \n",
    "            \n",
    "    if epoch == 0:\n",
    "        print(torch.cuda.memory_summary(device=cuda_device))\n",
    "        \n",
    "    if (epoch+1) % int(n_epoch/10) == 0:\n",
    "        print(tabulate([\n",
    "                        [\"epoch\", epoch+1], \n",
    "                        [\"total loss\", loss_epoch/total_num],\n",
    "                        [\"reconstruction error\", recon_loss/total_num],\n",
    "                        [\"KL divergence\", KLD_loss/total_num],\n",
    "                        [\"error ratio\", reconstruction_error/KL_divergence],\n",
    "                        ]))\n",
    "        print(\"%.2f minutes have passed\"%((time.time()-start)/60))\n",
    "        \n",
    "        fig, ax = plt.subplots(2, n_fig, figsize=(5*n_fig, 5*2))\n",
    "        for i in range(n_fig):\n",
    "            ax[0][i].imshow(x[i].data.cpu(), cmap=\"inferno\")\n",
    "            ax[1][i].imshow(x_[i].squeeze().data.cpu(), cmap=\"inferno\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "latent_z = np.asarray(latent_z)\n",
    "z_mu = np.asarray(z_mu)\n",
    "z_logvar = np.asarray(z_logvar)\n",
    "print(\"The training has been finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2071e619",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb9bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93a574",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.zeros_like(latent_z)\n",
    "coeffs[ri] = latent_z.copy()\n",
    "coeffs_reshape = reshape_coeff(coeffs, data_shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.grid()\n",
    "for i in range(num_comp):\n",
    "    ax.hist(coeffs[:, i], bins=50, alpha=(1.0-i*(1/num_comp)))\n",
    "plt.show()\n",
    "\n",
    "nrow, ncol = n_split, n_each_split\n",
    "print(nrow, ncol)\n",
    "\n",
    "for j in range(num_comp):\n",
    "    fig, ax = plt.subplots(nrow, ncol, figsize=(5*ncol, 5*nrow))\n",
    "    fig.suptitle(\"latent variable %d\"%(j+1), fontsize=20)\n",
    "    for k, a in enumerate(ax.flat):\n",
    "        a.imshow(coeffs_reshape[k][:, :, j], cmap=\"inferno\")\n",
    "        a.axis(\"off\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bec2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.zeros_like(z_mu)\n",
    "coeffs[ri] = z_mu.copy()\n",
    "coeffs_reshape = reshape_coeff(coeffs, data_shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.grid()\n",
    "for i in range(num_comp):\n",
    "    ax.hist(coeffs[:, i], bins=50, alpha=(1.0-i*(1/num_comp)))\n",
    "plt.show()\n",
    "\n",
    "nrow, ncol = n_split, n_each_split\n",
    "print(nrow, ncol)\n",
    "\n",
    "for j in range(num_comp):\n",
    "    fig, ax = plt.subplots(nrow, ncol, figsize=(5*ncol, 5*nrow))\n",
    "    fig.suptitle(\"latent variable %d\"%(j+1), fontsize=20)\n",
    "    for k, a in enumerate(ax.flat):\n",
    "        a.imshow(coeffs_reshape[k][:, :, j], cmap=\"inferno\")\n",
    "        a.axis(\"off\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068292a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.zeros_like(z_logvar)\n",
    "coeffs[ri] = np.exp(0.5*z_logvar)\n",
    "coeffs_reshape = reshape_coeff(coeffs, data_shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.grid()\n",
    "for i in range(num_comp):\n",
    "    ax.hist(coeffs[:, i], bins=50, alpha=(1.0-i*(1/num_comp)))\n",
    "plt.show()\n",
    "\n",
    "nrow, ncol = n_split, n_each_split\n",
    "print(nrow, ncol)\n",
    "\n",
    "for j in range(num_comp):\n",
    "    fig, ax = plt.subplots(nrow, ncol, figsize=(5*ncol, 5*nrow))\n",
    "    fig.suptitle(\"latent variable %d\"%(j+1), fontsize=20)\n",
    "    for k, a in enumerate(ax.flat):\n",
    "        a.imshow(coeffs_reshape[k][:, :, j], cmap=\"inferno\")\n",
    "        a.axis(\"off\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imsave(\"latent_variable_maps.tif\", coeffs_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 20\n",
    "sigma = 3.0\n",
    "z_test = np.linspace(-sigma, sigma, n_sample*10, endpoint=True)\n",
    "rv = stats.norm(0, 1)\n",
    "norm_pdf = rv.pdf(z_test)\n",
    "norm_pdf = norm_pdf / np.sum(norm_pdf)\n",
    "z_test = np.sort(np.random.choice(z_test, n_sample, replace=False, p=norm_pdf))\n",
    "z_test = np.meshgrid(z_test, z_test)\n",
    "z_test = np.stack((z_test[0].flatten(), z_test[1].flatten()), axis=1)\n",
    "print(z_test.shape)\n",
    "z_test = torch.from_numpy(z_test).to(torch.float32).to(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14627146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "generated = model.module.decode(z_test)\n",
    "print(generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec30134",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(n_sample, n_sample, figsize=(30, 30))\n",
    "for i, a in enumerate(ax.flat):\n",
    "    a.imshow(generated[i].squeeze().data.cpu(), cmap=\"inferno\")\n",
    "    a.axis(\"off\")\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2705a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(n_sample, n_sample, figsize=(30, 30))\n",
    "for i, a in enumerate(ax.flat):\n",
    "    tmp = generated[i].squeeze().data.cpu()\n",
    "    tmp = np.log(np.abs(np.fft.fftshift(np.fft.fft2(tmp))))\n",
    "    a.imshow(tmp, cmap=\"inferno\")\n",
    "    a.axis(\"off\")\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b95a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D subspace\n",
    "%matplotlib qt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "\n",
    "def projection(c1, c2):\n",
    "    ax.cla()\n",
    "    ax.scatter(coeffs[:, c1], coeffs[:, c2], s=30, c=\"black\", alpha=0.5)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel(\"loading vector %d\"%(c1+1), fontsize=15)\n",
    "    ax.set_ylabel(\"loading vector %d\"%(c2+1), fontsize=15)\n",
    "    ax.tick_params(axis=\"both\", labelsize=15)\n",
    "    fig.canvas.draw()\n",
    "    fig.tight_layout()\n",
    "\n",
    "x_widget = pyw.IntSlider(min=0, max=num_comp-1, step=1, value=0)\n",
    "y_widget = pyw.IntSlider(min=0, max=num_comp-1, step=1, value=1)\n",
    "\n",
    "pyw.interact(projection, c1=x_widget, c2=y_widget)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
