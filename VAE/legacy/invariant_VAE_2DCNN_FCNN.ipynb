{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from VAEs_module import *\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as pyw\n",
    "import tkinter.filedialog as tkf\n",
    "import tifffile\n",
    "from tabulate import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d670876",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_adr = tkf.askopenfilenames()\n",
    "print(*file_adr, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587da42-eee1-4bd4-b68e-846903d802f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load = load_data(file_adr, dat_dim=4, dat_unit='1/nm', rescale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2cdc2-f5f2-4d1a-ac8e-d2021480d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load.find_center(cbox_edge=7, center_remove=0, result_visual=True, log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41ddf8-4247-4355-859d-6b74daf5beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load.make_input(min_val=1E-6, max_normalize=True, \n",
    "           log_scale=False, radial_flat=False, \n",
    "           w_size=30, radial_range=None, final_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54efefaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"%d gpu available\"%(torch.cuda.device_count()))\n",
    "    cuda_device = torch.device(\"cuda:0\")\n",
    "    print(torch.cuda.get_device_name(cuda_device))\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "    print(torch.cuda.memory_summary(device=cuda_device))\n",
    "else:\n",
    "    cuda_device = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comp = 2\n",
    "channels = [32, 64, 128, 256]\n",
    "kernels = [4, 4, 4, 4]\n",
    "padding = [1, 1, 1, 1]\n",
    "stride = [2, 2, 2, 2]\n",
    "pooling = [1, 1, 1, 1]\n",
    "\n",
    "dat_dim = []\n",
    "tmp_dim = data_load.w_size*2\n",
    "for i in range(len(kernels)):\n",
    "    tmp_dim += (-kernels[i]+2*padding[i])\n",
    "    tmp_dim /= stride[i]\n",
    "    tmp_dim += 1\n",
    "    tmp_dim /= pooling[i]\n",
    "    dat_dim.append(int(tmp_dim))\n",
    "\n",
    "print(dat_dim)\n",
    "print(kernels)\n",
    "print(channels)\n",
    "print(padding)\n",
    "print(stride)\n",
    "print(pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289fdfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_check = True\n",
    "angle_std = np.pi/4\n",
    "translation_check = True\n",
    "translation_std = 0.1\n",
    "\n",
    "parallel_ = True\n",
    "\n",
    "enc_model = ivVAE2DCNN_encoder(dat_dim[-1], channels, kernels, stride, padding, pooling, \n",
    "                                  num_comp, rotation_check, translation_check, translation_std)\n",
    "if parallel_:\n",
    "    enc_model = nn.DataParallel(enc_model)\n",
    "enc_model.cuda(cuda_device)\n",
    "print(enc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8533ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "mini_batches = [data_load.dataset_input[k:k+batch_size] for k in range(0, len(data_load.dataset_input), batch_size)]\n",
    "print(len(mini_batches))\n",
    "print(len(mini_batches[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(1, -1, data_load.w_size*2)\n",
    "X, Y = np.meshgrid(grid, grid)\n",
    "img_coord = np.stack([X.ravel(), Y.ravel()], 1)\n",
    "img_coord = torch.from_numpy(img_coord)\n",
    "img_coord = img_coord.to(torch.float32)\n",
    "img_coord = img_coord.requires_grad_(requires_grad=False)\n",
    "n_dim = img_coord.size(1)\n",
    "print(img_coord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = img_coord.expand(batch_size, img_coord.size(0), img_coord.size(1))\n",
    "coord = coord.requires_grad_(requires_grad=False)\n",
    "coord = coord.to(cuda_device)\n",
    "n_coord = coord.size(1)\n",
    "print(n_coord)\n",
    "print(coord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ab051",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_dim = 512\n",
    "num_hid = 1\n",
    "dec_model = ivVAEFCNN_decoder(n_coord, n_dim, num_comp, hid_dim, num_hid, data_load.w_size*2, bi_lin=True)\n",
    "\n",
    "if parallel_:\n",
    "    dec_model = nn.DataParallel(dec_model)\n",
    "    \n",
    "dec_model.cuda(cuda_device)\n",
    "print(dec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d984980",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "l_rate = 0.01\n",
    "params = list(enc_model.parameters()) + list(dec_model.parameters())\n",
    "optimizer = optim.Adam(params, lr=l_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ef0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "loss_plot = []\n",
    "n_fig = 5\n",
    "for epoch in range(n_epoch):\n",
    "    loss_epoch = 0\n",
    "    recon_loss = 0\n",
    "    KLD_loss = 0\n",
    "    KLD_rot_loss = 0\n",
    "    \n",
    "    latent_z = []\n",
    "    z_mu = []\n",
    "    z_logvar = []\n",
    "    rot_theta = []\n",
    "    trans_delta = []\n",
    "    for i, m_batch in enumerate(mini_batches):\n",
    "        \n",
    "        x = torch.from_numpy(m_batch).clamp_(min=0.001, max=0.999)\n",
    "        x = x.to(torch.float32)\n",
    "        x = x.to(cuda_device)\n",
    "        x.requires_grad_(requires_grad=False)\n",
    "        \n",
    "        tf_coord, mu, logvar, z, rot_mu, rot_logvar, rot_z, trans_z = enc_model(x, coord)\n",
    "        x_ = dec_model(tf_coord.contiguous(), z)\n",
    "        \n",
    "        x_ = x_.view(-1, data_load.w_size*2, data_load.w_size*2)\n",
    "\n",
    "        reconstruction_error = F.binary_cross_entropy(x_, x, reduction=\"sum\")\n",
    "        KL_divergence = -0.5*torch.sum(1+logvar-mu**2-logvar.exp())\n",
    "        KL_divergence_rot = torch.sum(-rot_logvar + np.log(angle_std) + (torch.exp(rot_logvar)**2 + \n",
    "                                                              rot_mu**2)/2/angle_std**2 - 0.5)\n",
    "        \n",
    "        loss = reconstruction_error + KL_divergence + KL_divergence_rot\n",
    "        \n",
    "        loss_epoch += loss.item()\n",
    "        recon_loss += reconstruction_error.item()\n",
    "        KLD_loss += KL_divergence.item()\n",
    "        KLD_rot_loss += KL_divergence_rot.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        latent_z.extend(z.data.cpu().numpy().tolist())\n",
    "        z_mu.extend(mu.data.cpu().numpy().tolist())\n",
    "        z_logvar.extend(logvar.data.cpu().numpy().tolist())\n",
    "        rot_theta.extend(rot_z.data.cpu().numpy().tolist())\n",
    "        if translation_check:\n",
    "            trans_delta.extend(trans_z.data.cpu().numpy().tolist())\n",
    "    \n",
    "    loss_plot.append(loss_epoch/data_load.total_num)\n",
    "    \n",
    "    latent_z = np.asarray(latent_z)\n",
    "    z_mu = np.asarray(z_mu)\n",
    "    z_logvar = np.asarray(z_logvar)\n",
    "    rot_theta = np.asarray(rot_theta)\n",
    "    trans_delta = np.asarray(trans_delta)\n",
    "            \n",
    "            \n",
    "    if epoch == 0:\n",
    "        print(torch.cuda.memory_summary(device=cuda_device))\n",
    "        \n",
    "    if (epoch+1) % int(n_epoch/10) == 0:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.plot(np.arange(epoch+1)+1, loss_plot, \"k-\")\n",
    "        ax.grid()\n",
    "        plt.show()\n",
    "        \n",
    "        print(tabulate([\n",
    "                        [\"epoch\", epoch+1], \n",
    "                        [\"total loss\", loss_epoch/data_load.total_num],\n",
    "                        [\"reconstruction error\", recon_loss/data_load.total_num],\n",
    "                        [\"KL divergence\", KLD_loss/data_load.total_num],\n",
    "                        [\"KL divergence (rotation)\", KLD_rot_loss/data_load.total_num],\n",
    "                        ]))\n",
    "        print(\"%.2f minutes have passed\"%((time.time()-start)/60))\n",
    "        \n",
    "        fig, ax = plt.subplots(2, n_fig, figsize=(5*n_fig, 5*2))\n",
    "        for i in range(n_fig):\n",
    "            ax[0][i].imshow(x[i].data.cpu().numpy().astype(np.float32), cmap=\"inferno\")\n",
    "            ax[1][i].imshow(x_[i].data.cpu().numpy().astype(np.float32), cmap=\"inferno\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        coeffs = np.zeros_like(latent_z)\n",
    "        coeffs[data_load.ri] = latent_z.copy()\n",
    "        coeffs_reshape = reshape_coeff(coeffs, data_load.data_shape)  \n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.grid()\n",
    "        for i in range(num_comp):\n",
    "            ax.hist(coeffs[:, i], bins=50, alpha=(1.0-i*(1/num_comp)))\n",
    "        plt.show()\n",
    "\n",
    "        if data_load.num_img != 1:\n",
    "            for i in range(num_comp):\n",
    "                fig, ax = plt.subplots(1, data_load.num_img, figsize=(7*data_load.num_img, 7))\n",
    "                for j in range(data_load.num_img):\n",
    "                    tmp = ax[j].imshow(coeffs_reshape[j][:, :, i], cmap=\"viridis\")\n",
    "                    ax[j].axis(\"off\")\n",
    "                    #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "                plt.show()\n",
    "        else:            \n",
    "            for i in range(num_comp):\n",
    "                fig, ax = plt.subplots(1, 1, figsize=(7, 7*data_load.num_img))\n",
    "                tmp = ax.imshow(coeffs_reshape[0][:, :, i], cmap=\"viridis\")\n",
    "                ax.axis(\"off\")\n",
    "                #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "                plt.show()\n",
    "\n",
    "print(\"The training has been finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e1a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.zeros_like(latent_z)\n",
    "coeffs[data_load.ri] = latent_z.copy()\n",
    "coeffs_reshape = reshape_coeff(coeffs, data_load.data_shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.grid()\n",
    "for i in range(num_comp):\n",
    "    ax.hist(coeffs[:, i], bins=50, alpha=(1.0-i*(1/num_comp)))\n",
    "plt.show()\n",
    "\n",
    "if data_load.num_img != 1:\n",
    "    for i in range(num_comp):\n",
    "        fig, ax = plt.subplots(1, data_load.num_img, figsize=(7*data_load.num_img, 7))\n",
    "        for j in range(data_load.num_img):\n",
    "            tmp = ax[j].imshow(coeffs_reshape[j][:, :, i], cmap=\"viridis\")\n",
    "            ax[j].axis(\"off\")\n",
    "            #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()\n",
    "else:            \n",
    "    for i in range(num_comp):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7, 7*data_load.num_img))\n",
    "        tmp = ax.imshow(coeffs_reshape[0][:, :, i], cmap=\"viridis\")\n",
    "        ax.axis(\"off\")\n",
    "        #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093dc52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rotation_check:\n",
    "    rot_theta = np.expand_dims(rot_theta, axis=1)\n",
    "    coeffs = np.zeros_like(rot_theta)\n",
    "    coeffs[data_load.ri] = rot_theta.copy()\n",
    "    coeffs_reshape = reshape_coeff(coeffs, data_load.data_shape)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.grid()\n",
    "    ax.hist(coeffs[:], bins=50, alpha=(1.0-i*(1/num_comp)))\n",
    "    plt.show()\n",
    "\n",
    "    if data_load.num_img != 1:\n",
    "        fig, ax = plt.subplots(1, data_load.num_img, figsize=(7*data_load.num_img, 7))\n",
    "        for j in range(data_load.num_img):\n",
    "            tmp = ax[j].imshow(coeffs_reshape[j][:, :], cmap=\"viridis\")\n",
    "            ax[j].axis(\"off\")\n",
    "            #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()\n",
    "    else:            \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7, 7*data_load.num_img))\n",
    "        tmp = ax.imshow(coeffs_reshape[0][:, :], cmap=\"viridis\")\n",
    "        ax.axis(\"off\")\n",
    "        #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d425f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if translation_check:\n",
    "    coeffs = np.zeros_like(trans_delta)\n",
    "    coeffs[data_load.ri] = trans_delta.copy()\n",
    "    coeffs_reshape = reshape_coeff(coeffs, data_load.data_shape)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.grid()\n",
    "    for i in range(2):\n",
    "        ax.hist(coeffs[:, i], bins=50, alpha=(1.0-i*(1/num_comp)))\n",
    "    plt.show()\n",
    "\n",
    "    if data_load.num_img != 1:\n",
    "        for i in range(2):\n",
    "            fig, ax = plt.subplots(1, data_load.num_img, figsize=(7*data_load.num_img, 7))\n",
    "            for j in range(data_load.num_img):\n",
    "                tmp = ax[j].imshow(coeffs_reshape[j][:, :, i], cmap=\"viridis\")\n",
    "                ax[j].axis(\"off\")\n",
    "                #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "            plt.show()\n",
    "    else:            \n",
    "        for i in range(2):\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(7, 7*data_load.num_img))\n",
    "            tmp = ax.imshow(coeffs_reshape[0][:, :, i], cmap=\"viridis\")\n",
    "            ax.axis(\"off\")\n",
    "            #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3acb243",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 20\n",
    "sigma = 5.0\n",
    "z_test = np.linspace(-sigma, sigma, n_sample*10, endpoint=True)\n",
    "rv = stats.norm(0, 1)\n",
    "norm_pdf = rv.pdf(z_test)\n",
    "norm_pdf = norm_pdf / np.sum(norm_pdf)\n",
    "z_test = np.sort(np.random.choice(z_test, n_sample, replace=False, p=norm_pdf))\n",
    "z_test = np.meshgrid(z_test, z_test)\n",
    "z_test = np.stack((z_test[0].flatten(), z_test[1].flatten()), axis=1)\n",
    "print(z_test.shape)\n",
    "z_test = torch.from_numpy(z_test).to(torch.float32).to(cuda_device)\n",
    "\n",
    "coord_test = img_coord.expand(n_sample**2, img_coord.size(0), img_coord.size(1))\n",
    "coord_test = coord_test.to(cuda_device)\n",
    "print(coord_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_model.eval()\n",
    "generated = dec_model(coord_test.contiguous(), z_test)\n",
    "print(generated.shape)\n",
    "generated = generated.view(n_sample**2, data_load.w_size*2, data_load.w_size*2)\n",
    "print(generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f7309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(n_sample, n_sample, figsize=(30, 30))\n",
    "for i, a in enumerate(ax.flat):\n",
    "    a.imshow(generated[i].squeeze().data.cpu().numpy().astype(np.float32), cmap=\"jet\")\n",
    "    a.axis(\"off\")\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
