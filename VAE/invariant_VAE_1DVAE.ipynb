{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8849712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import tifffile\n",
    "import ipywidgets as pyw\n",
    "import tkinter.filedialog as tkf\n",
    "from tabulate import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ab204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a customized colorbar\n",
    "color_rep = [\"black\", \"red\", \"green\", \"blue\", \"orange\", \"purple\", \"yellow\", \"lime\", \n",
    "             \"cyan\", \"magenta\", \"lightgray\", \"peru\", \"springgreen\", \"deepskyblue\", \n",
    "             \"hotpink\", \"darkgray\"]\n",
    "print(len(color_rep))\n",
    "custom_cmap = mcolors.ListedColormap(color_rep)\n",
    "bounds = np.arange(-1, len(color_rep))\n",
    "norm = mcolors.BoundaryNorm(boundaries=bounds, ncolors=len(color_rep))\n",
    "sm = cm.ScalarMappable(cmap=custom_cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "cm_rep = [\"gray\", \"Reds\", \"Greens\", \"Blues\", \"Oranges\", \"Purples\"]\n",
    "print(len(cm_rep))\n",
    "\n",
    "def zero_one_rescale(spectrum):\n",
    "    \"\"\"\n",
    "    normalize one spectrum from 0.0 to 1.0\n",
    "    \"\"\"\n",
    "    spectrum = spectrum.clip(min=0.0)\n",
    "    min_val = np.min(spectrum)\n",
    "    \n",
    "    rescaled = spectrum - min_val\n",
    "    \n",
    "    if np.max(rescaled) != 0:\n",
    "        rescaled = rescaled / np.max(rescaled)\n",
    "    \n",
    "    return rescaled\n",
    "\n",
    "def indices_at_r(shape, radius, center=None):\n",
    "    y, x = np.indices(shape)\n",
    "    if not center:\n",
    "        center = np.array([(y.max()-y.min())/2.0, (x.max()-x.min())/2.0])\n",
    "    r = np.hypot(y - center[0], x - center[1])\n",
    "    r = np.around(r)\n",
    "    \n",
    "    ri = np.where(r == radius)\n",
    "    \n",
    "    angle_arr = np.zeros(shape)\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            angle_arr[i, j] = np.angle(complex(x[i, j]-center[1], y[i, j]-center[0]), deg=True)\n",
    "            \n",
    "    angle_arr = angle_arr + 180\n",
    "    angle_arr = np.around(angle_arr)\n",
    "    \n",
    "    ai = np.argsort(angle_arr[ri])\n",
    "    r_sort = (ri[1][ai], ri[0][ai])\n",
    "    a_sort = np.sort(angle_arr[ri])\n",
    "        \n",
    "    return r_sort, a_sort\n",
    "\n",
    "def circle_flatten(f_stack, radial_range, c_pos):\n",
    "    k_indx = []\n",
    "    k_indy = []\n",
    "    \n",
    "    for r in range(radial_range[0], radial_range[1], radial_range[2]):\n",
    "        tmp_k, tmp_a = indices_at_r(f_stack.shape[2:], r, c_pos)\n",
    "        k_indx.extend(tmp_k[0].tolist())\n",
    "        k_indy.extend(tmp_k[1].tolist())\n",
    "    \n",
    "    k_indx = np.asarray(k_indx)\n",
    "    k_indy = np.asarray(k_indy)\n",
    "    flat_data = f_stack[:, :, k_indy, k_indx]\n",
    "    \n",
    "    return flat_data\n",
    "\n",
    "def flattening(fdata, flat_option=\"box\", crop_dist=None, c_pos=None):\n",
    "    \n",
    "    fdata_shape = fdata.shape\n",
    "    if flat_option == \"box\":\n",
    "        if crop_dist:     \n",
    "            box_size = np.array([crop_dist, crop_dist])\n",
    "        \n",
    "            for i in range(num_img):\n",
    "                h_si = np.floor(c_pos[0]-box_size[0]).astype(int)\n",
    "                h_fi = np.ceil(c_pos[0]+box_size[0]).astype(int)\n",
    "                w_si = np.floor(c_pos[1]-box_size[1]).astype(int)\n",
    "                w_fi = np.ceil(c_pos[1]+box_size[1]).astype(int)\n",
    "\n",
    "            tmp = fdata[:, :, h_si:h_fi, w_si:w_fi]\n",
    "            \n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "            ax.imshow(np.log(np.mean(tmp, axis=(0, 1))), cmap=\"viridis\")\n",
    "            ax.axis(\"off\")\n",
    "            plt.show()\n",
    "            \n",
    "            tmp = tmp.reshape(fdata_shape[0], fdata_shape[1], -1)\n",
    "            return tmp\n",
    "\n",
    "        else:\n",
    "            tmp = fdata.reshape(fdata_shape[0], fdata_shape[1], -1)\n",
    "            return tmp\n",
    "\n",
    "        \n",
    "    elif flat_option == \"radial\":\n",
    "        if len(crop_dist) != 3:\n",
    "            print(\"Warning! 'crop_dist' must be a list containing 3 elements\")\n",
    "            \n",
    "        tmp = circle_flatten(fdata, crop_dist, c_pos)\n",
    "        return tmp\n",
    "        \n",
    "    else:\n",
    "        print(\"Warning! Wrong option ('flat_option')\")\n",
    "        return\n",
    "\n",
    "def fourd_roll_axis(stack):\n",
    "    stack = np.rollaxis(np.rollaxis(stack, 2, 0), 3, 1)\n",
    "    return stack\n",
    "\n",
    "def reshape_coeff(coeffs, new_shape):\n",
    "    \"\"\"\n",
    "    reshape a coefficient matrix to restore the original scanning shapes.\n",
    "    \"\"\"\n",
    "    coeff_reshape = []\n",
    "    for i in range(len(new_shape)):\n",
    "        temp = coeffs[:int(new_shape[i, 0]*new_shape[i, 1]), :]\n",
    "        coeffs = np.delete(coeffs, range(int(new_shape[i, 0]*new_shape[i, 1])), axis=0)\n",
    "        temp = np.reshape(temp, (new_shape[i, 0], new_shape[i, 1], -1))\n",
    "        #print(temp.shape)\n",
    "        coeff_reshape.append(temp)\n",
    "        \n",
    "    return coeff_reshape\n",
    "\n",
    "def radial_indices(shape, radial_range, center=None):\n",
    "    y, x = np.indices(shape)\n",
    "    if not center:\n",
    "        center = np.array([(y.max()-y.min())/2.0, (x.max()-x.min())/2.0])\n",
    "    \n",
    "    r = np.hypot(y - center[0], x - center[1])\n",
    "    ri = np.ones(r.shape)\n",
    "    \n",
    "    if len(np.unique(radial_range)) > 1:\n",
    "        ri[np.where(r <= radial_range[0])] = 0\n",
    "        ri[np.where(r > radial_range[1])] = 0\n",
    "        \n",
    "    else:\n",
    "        r = np.round(r)\n",
    "        ri[np.where(r != round(radial_range[0]))] = 0\n",
    "    \n",
    "    return ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_adr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c3f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_adr.extend(tkf.askopenfilenames())\n",
    "print(len(file_adr))\n",
    "print(*file_adr, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b5d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_img = len(file_adr)\n",
    "print(num_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 4D-STEM data\n",
    "data_original = []\n",
    "data_shape = []\n",
    "for i in range(num_img):\n",
    "    tmp = tifffile.imread(file_adr[i])\n",
    "    print(tmp.shape)\n",
    "    data_shape.append(list(tmp.shape[:2]))\n",
    "    data_original.append(tmp)\n",
    "    \n",
    "data_shape = np.asarray(data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b43bd8-33bf-4d0c-9878-5cdc3ad34ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the center position\n",
    "center_pos = []\n",
    "cbox_edge = 100\n",
    "center_removed_ = False\n",
    "for i in range(num_img):\n",
    "    mean_dp = np.mean(data_original[i], axis=(0, 1))\n",
    "    cbox_outy = int(mean_dp.shape[0]/2 - cbox_edge/2)\n",
    "    cbox_outx = int(mean_dp.shape[1]/2 - cbox_edge/2)\n",
    "    center_box = mean_dp[cbox_outy:-cbox_outy, cbox_outx:-cbox_outx]\n",
    "    Y, X = np.indices(center_box.shape)\n",
    "    com_y = np.sum(center_box * Y) / np.sum(center_box)\n",
    "    com_x = np.sum(center_box * X) / np.sum(center_box)\n",
    "    c_pos = [np.around(com_y+cbox_outy), np.around(com_x+cbox_outx)]\n",
    "    center_pos.append(c_pos)\n",
    "print(center_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8473fb-888b-4f03-b7e9-a205f7af93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore')\n",
    "for i in range(num_img):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(np.log(np.mean(data_original[i], axis=(0, 1))), cmap=\"viridis\")\n",
    "    ax.scatter(center_pos[i][1], center_pos[i][0], c=\"r\", s=10)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bcfb72-a60b-493c-b9b2-f2c9b62e4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of the center beam (optional)\n",
    "center_removed_ = True\n",
    "center_radius = 10\n",
    "data_cr = []\n",
    "for i in range(num_img):\n",
    "    ri = radial_indices(data_original[i].shape[2:], [center_radius, 100], center=center_pos[i])\n",
    "    data_cr.append(np.multiply(data_original[i], ri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420ff01-e8be-4add-a048-844a8b246648",
   "metadata": {},
   "outputs": [],
   "source": [
    "if center_removed_:\n",
    "    for i in range(num_img):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "        ax.imshow(np.log(np.mean(data_cr[i], axis=(0, 1))), cmap=\"viridis\")\n",
    "        ax.scatter(center_pos[i][1], center_pos[i][0], c=\"r\", s=10)\n",
    "        ax.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da51919-4cd3-44a5-971f-6347a5e4a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D diffraction pattern -> 1D data\n",
    "# option 1 : flatten a box\n",
    "radial_flat_ = False\n",
    "\n",
    "dataset = []\n",
    "w_size = 30\n",
    "for i in range(num_img):\n",
    "    if center_removed_:\n",
    "        flattened = flattening(data_cr[i], flat_option=\"box\", crop_dist=w_size, c_pos=center_pos[i])\n",
    "    \n",
    "    else:\n",
    "        flattened = flattening(data_original[i], flat_option=\"box\", crop_dist=w_size, c_pos=center_pos[i])\n",
    "    \n",
    "    dataset.append(flattened)\n",
    "    \n",
    "s_length = (w_size*2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3445be0-b7b3-4b1b-93b8-ce0bd2d751e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D diffraction pattern -> 1D data\n",
    "# option 2 : flatten radially\n",
    "radial_flat_ = True\n",
    "\n",
    "dataset = []\n",
    "radial_range = [44, 64, 1]\n",
    "k_indx = []\n",
    "k_indy = []\n",
    "a_ind = []\n",
    "\n",
    "for r in range(radial_range[0], radial_range[1], radial_range[2]):\n",
    "    tmp_k, tmp_a = indices_at_r((radial_range[1]*2, radial_range[1]*2), r, (radial_range[1], radial_range[1]))\n",
    "    k_indx.extend(tmp_k[0].tolist())\n",
    "    k_indy.extend(tmp_k[1].tolist())\n",
    "    a_ind.extend(tmp_a.tolist())\n",
    "    \n",
    "s_length = len(k_indx)\n",
    "\n",
    "k_indx = np.asarray(k_indx)\n",
    "k_indy = np.asarray(k_indy)\n",
    "a_ind = np.asarray(a_ind)\n",
    "print(k_indx.shape, k_indy.shape, a_ind.shape)\n",
    "\n",
    "for i in range(num_img):\n",
    "    if center_removed_:\n",
    "        flattened = circle_flatten(data_cr[i], radial_range, center_pos[i])\n",
    "    else:\n",
    "        flattened = circle_flatten(data_original[i], radial_range, center_pos[i])\n",
    "        \n",
    "    dataset.append(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd090ffb-d58d-4672-afd9-0f6010eb77ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the input dataset\n",
    "dataset_flat = []\n",
    "for i in range(num_img):\n",
    "    print(dataset[i].shape)\n",
    "    dataset_flat.extend(dataset[i].reshape(-1, s_length))\n",
    "dataset_flat = np.asarray(dataset_flat).clip(min=0.0)\n",
    "print(dataset_flat.min(), dataset_flat.max())\n",
    "print(dataset_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab8f7c-a9db-442e-91b8-69a4848bcf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert values into log scale (optional)\n",
    "dataset_flat[np.where(dataset_flat==0.0)] = 1.0\n",
    "dataset_flat = np.log(dataset_flat)\n",
    "print(dataset_flat.min(), dataset_flat.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7996ece-6eb2-4847-a36b-47a49adf074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max-normalize each flattened diffraction pattern (optional)\n",
    "dataset_flat = dataset_flat / np.max(dataset_flat, axis=1)[:, np.newaxis]\n",
    "dataset_flat = dataset_flat.clip(min=0.0)\n",
    "print(dataset_flat.min(), dataset_flat.max())\n",
    "print(dataset_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2348624",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = len(dataset_flat)\n",
    "ri = np.random.choice(total_num, total_num, replace=False)\n",
    "\n",
    "dataset_input = dataset_flat[ri]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class invar1DVAE_encoder(nn.Module):\n",
    "    def __init__(self,  in_dim, h_dim, z_dim, rot_check=True, trans_check=True, trans_std=0.1):\n",
    "        super(invar1DVAE_encoder, self).__init__()\n",
    "        \n",
    "        self.img_z_dim = z_dim        \n",
    "        \n",
    "        self.rot_check=rot_check\n",
    "        self.trans_check=trans_check\n",
    "        self.trans_std=trans_std\n",
    "        \n",
    "        self.z_dim = self.img_z_dim\n",
    "        if self.rot_check:\n",
    "            self.z_dim += 1\n",
    "        if self.trans_check:\n",
    "            self.z_dim += 2\n",
    "        if not self.rot_check and not self.trans_check:\n",
    "            print(\"Warning! at least one invariant property must be chosen\")\n",
    "            return\n",
    "        \n",
    "        enc_net = []\n",
    "        enc_net.append(nn.Linear(in_dim, h_dim[0]))\n",
    "        enc_net.append(nn.LeakyReLU(0.1))\n",
    "        for i in range(1, len(h_dim)):\n",
    "            enc_net.append(nn.Linear(h_dim[i-1], h_dim[i]))\n",
    "            enc_net.append(nn.LeakyReLU(0.1))\n",
    "        enc_net.append(nn.Linear(h_dim[-1], 2*self.z_dim))\n",
    "        \n",
    "        self.encoder = nn.Sequential(*enc_net)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \n",
    "        latent = self.encoder(x)\n",
    "        mu = latent[:, :self.z_dim]\n",
    "        logvar = latent[:, self.z_dim:]\n",
    "        \n",
    "        return mu, logvar\n",
    "        \n",
    "    def rotation(self, coord, z):\n",
    "        rot_matrix = torch.stack((torch.cos(z), torch.sin(z), -torch.sin(z), torch.cos(z)), dim=1)\n",
    "        rot_matrix = rot_matrix.view(-1, 2, 2)\n",
    "        \n",
    "        return torch.bmm(coord, rot_matrix)\n",
    "        \n",
    "        \n",
    "    def translation(self, coord, z):\n",
    "        trans_z = z * self.trans_std\n",
    "        trans_z = trans_z.unsqueeze(1)\n",
    "        \n",
    "        return coord + trans_z\n",
    "        \n",
    "                \n",
    "    def reparametrization(self, mu, logvar):\n",
    "        \n",
    "        return mu+torch.exp(0.5*logvar)*torch.randn_like(logvar)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, coord):\n",
    "        if coord.size(0) != x.size(0):\n",
    "            coord = coord[:x.size(0)]\n",
    "        \n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrization(mu, logvar)\n",
    "        \n",
    "        rot_mu=None\n",
    "        rot_logvar=None\n",
    "        rot_z=None\n",
    "        \n",
    "        trans_mu=None\n",
    "        trans_logvar=None\n",
    "        trans_z=None\n",
    "        \n",
    "        if self.rot_check:\n",
    "            rot_mu = mu[:, 0]\n",
    "            mu = mu[:, 1:]\n",
    "            \n",
    "            rot_logvar = logvar[:, 0]\n",
    "            logvar = logvar[:, 1:]\n",
    "            \n",
    "            rot_z = z[:, 0]\n",
    "            z = z[:, 1:]\n",
    "            \n",
    "            coord = self.rotation(coord, rot_z)\n",
    "            \n",
    "        if self.trans_check:\n",
    "            \n",
    "            trans_z = z[:, 2:]\n",
    "            z = z[:, 2:]\n",
    "            \n",
    "            coord = self.translation(coord, trans_z)\n",
    "        \n",
    "        return coord, mu, logvar, z, rot_mu, rot_logvar, rot_z, trans_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2d1a49-490a-449f-a263-b76d0af62edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class invar1DVAE_decoder(nn.Module):\n",
    "    def __init__(self, n_coord, n_dim, z_dim, hid_dim, num_hid, bi_lin=False):\n",
    "        super(invar1DVAE_decoder, self).__init__()\n",
    "        \n",
    "        self.n_coord = n_coord\n",
    "        self.n_dim = n_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.bi_lin = bi_lin\n",
    "        \n",
    "        self.linear_coord = nn.Linear(n_dim, hid_dim, bias=False)\n",
    "        self.linear_img = nn.Linear(z_dim, hid_dim, bias=False)\n",
    "        if bi_lin:\n",
    "            self.bi_linear = nn.Bilinear(n_dim, z_dim, hid_dim, bias=False)\n",
    "    \n",
    "        \n",
    "        dec_net = []\n",
    "        for i in range(num_hid):\n",
    "            dec_net.append(nn.Linear(hid_dim, hid_dim, bias=True))\n",
    "            dec_net.append(nn.BatchNorm1d(hid_dim))\n",
    "            dec_net.append(nn.Tanh())\n",
    "            \n",
    "        dec_net.append(nn.Linear(hid_dim, 1, bias=True))\n",
    "        dec_net.append(nn.Sigmoid())\n",
    "        \n",
    "        self.decoder = nn.Sequential(*dec_net)\n",
    "        \n",
    "        \n",
    "    def forward(self, coord, z):\n",
    "        img_tmp = self.linear_img(z)\n",
    "        z = z.unsqueeze(1)\n",
    "        z = z.expand(z.size(0), self.n_coord, self.z_dim).contiguous()\n",
    "        if self.bi_lin:\n",
    "            bi_tmp = self.bi_linear(coord, z)\n",
    "        coord = coord.view(coord.size(0)*coord.size(1), -1).contiguous()\n",
    "        coord_tmp = self.linear_coord(coord)\n",
    "        \n",
    "        #print(img_tmp.shape, bi_tmp.shape, coord_tmp.shape)\n",
    "        img_tmp = img_tmp.unsqueeze(1)\n",
    "        coord_tmp = coord_tmp.view(z.size(0), self.n_coord, -1)\n",
    "        #print(img_tmp.shape, bi_tmp.shape, coord_tmp.shape)\n",
    "        \n",
    "        \n",
    "        if self.bi_lin:\n",
    "            init_dec = coord_tmp + img_tmp + bi_tmp\n",
    "        else:\n",
    "            init_dec = coord_tmp + img_tmp\n",
    "        #print(init_dec.shape)\n",
    "        \n",
    "        init_dec = init_dec.view(z.size(0)*self.n_coord, -1)\n",
    "        output = self.decoder(init_dec.contiguous())\n",
    "        \n",
    "        return output.view(z.size(0), self.n_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f596f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"%d gpu available\"%(torch.cuda.device_count()))\n",
    "    cuda_device = torch.device(\"cuda:0\")\n",
    "    print(torch.cuda.get_device_name(cuda_device))\n",
    "    torch.cuda.set_device(cuda_device)\n",
    "    print(torch.cuda.memory_summary(device=cuda_device))\n",
    "else:\n",
    "    cuda_device = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a49cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "mini_batches = [dataset_input[k:k+batch_size] for k in range(0, len(dataset_input), batch_size)]\n",
    "print(len(mini_batches))\n",
    "print(len(mini_batches[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b5599-5ba4-4dab-a832-647d210213e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if radial_flat_:\n",
    "    img_coord = np.stack([k_indx, k_indy], 1)\n",
    "    img_coord = torch.from_numpy(img_coord)\n",
    "    img_coord = img_coord.to(torch.float32)\n",
    "    img_coord = img_coord.requires_grad_(requires_grad=False)\n",
    "    n_dim = img_coord.size(1)\n",
    "    print(img_coord.shape)\n",
    "    \n",
    "else:\n",
    "    grid = np.linspace(1, -1, w_size)\n",
    "    X, Y = np.meshgrid(grid, grid)\n",
    "    img_coord = np.stack([X.ravel(), Y.ravel()], 1)\n",
    "    img_coord = torch.from_numpy(img_coord)\n",
    "    img_coord = img_coord.to(torch.float32)\n",
    "    img_coord = img_coord.requires_grad_(requires_grad=False)\n",
    "    n_dim = img_coord.size(1)\n",
    "    print(img_coord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e953e-138c-4638-8450-d72680ccc9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = img_coord.expand(batch_size, img_coord.size(0), img_coord.size(1))\n",
    "coord = coord.requires_grad_(requires_grad=False)\n",
    "coord = coord.to(cuda_device)\n",
    "n_coord = coord.size(1)\n",
    "print(n_coord)\n",
    "print(coord.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f5d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_dim = [256, 256]\n",
    "num_comp = 2\n",
    "\n",
    "rotation_check = True\n",
    "angle_std = np.pi/4\n",
    "translation_check = False\n",
    "translation_std = 0.1\n",
    "\n",
    "enc_model = invar1DVAE_encoder(s_length, h_dim, num_comp, \n",
    "                           rotation_check, translation_check, translation_std)\n",
    "enc_model.cuda(cuda_device)\n",
    "print(enc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746a255-ecb2-4038-b204-78bf8e965410",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_dim = 256\n",
    "num_hid = 1\n",
    "parallel_ = True\n",
    "dec_model = invar1DVAE_decoder(n_coord, n_dim, num_comp, hid_dim, num_hid, bi_lin=True)\n",
    "if parallel_:\n",
    "    dec_model = nn.DataParallel(dec_model)\n",
    "dec_model.cuda(cuda_device)\n",
    "print(dec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4307b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "l_rate = 0.01\n",
    "params = list(enc_model.parameters()) + list(dec_model.parameters())\n",
    "optimizer = optim.Adam(params, lr=l_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd73357-efaf-4cd1-9f89-2dca3c165151",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    x = torch.from_numpy(mini_batches[i]).clamp_(min=1E-3, max=1-1E-3)\n",
    "    x = x.to(torch.float32)\n",
    "    x = x.to(cuda_device)\n",
    "    x.requires_grad_(requires_grad=False)\n",
    "    \n",
    "    #with torch.cuda.amp.autocast():\n",
    "    tf_coord, mu, logvar, z, rot_mu, rot_logvar, rot_z, trans_mu, trans_logvar, trans_z = enc_model(x, coord)\n",
    "    x_ = dec_model(tf_coord.contiguous(), z)\n",
    "    \n",
    "    print(x.shape, x_.shape)\n",
    "    print(x.min(), x.max())\n",
    "    print(x_.min(), x_.max())\n",
    "    print(x.dtype, x_.dtype)\n",
    "    \n",
    "    reconstruction_error = F.binary_cross_entropy(x_, x, reduction=\"mean\")\n",
    "    KL_divergence = -0.5*torch.mean(1+logvar-mu**2-logvar.exp())\n",
    "    KL_divergence_rot = torch.mean(-rot_logvar + np.log(angle_std) + (torch.exp(rot_logvar)**2 + \n",
    "                                                              rot_mu**2)/2/angle_std**2 - 0.5)\n",
    "        \n",
    "    loss = reconstruction_error + KL_divergence + KL_divergence_rot\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #if torch.isinf(reconstruction_error):\n",
    "    #    print(x.shape)\n",
    "    #    print(x_.shape)\n",
    "    #    print(x.min(), x.max())\n",
    "    #    print(x_.min(), x_.max())   \n",
    "    #    print(i, reconstruction_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c1ae3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "latent_z = []\n",
    "z_mu = []\n",
    "z_logvar = []\n",
    "rot_theta = []\n",
    "trans_delta = []\n",
    "n_fig = 5\n",
    "for epoch in range(n_epoch):\n",
    "    loss_epoch = 0\n",
    "    recon_loss = 0\n",
    "    KLD_loss = 0\n",
    "    KLD_rot_loss = 0\n",
    "    for i, m_batch in enumerate(mini_batches):\n",
    "        \n",
    "        x = torch.from_numpy(m_batch).clamp_(min=0.001, max=0.999)\n",
    "        x = x.to(torch.float32)\n",
    "        x = x.to(cuda_device)\n",
    "        x.requires_grad_(requires_grad=False)\n",
    "        \n",
    "        tf_coord, mu, logvar, z, rot_mu, rot_logvar, rot_z, trans_z = enc_model(x, coord)\n",
    "        x_ = dec_model(tf_coord.contiguous(), z)\n",
    "        print(x.min(), x.max())\n",
    "        print(x_.min(), x_.max())\n",
    "        \n",
    "        reconstruction_error = F.binary_cross_entropy(x_, x, reduction=\"sum\")\n",
    "        KL_divergence = -0.5*torch.sum(1+logvar-mu**2-logvar.exp())\n",
    "        KL_divergence_rot = torch.sum(-rot_logvar + np.log(angle_std) + (torch.exp(rot_logvar)**2 + \n",
    "                                                              rot_mu**2)/2/angle_std**2 - 0.5)\n",
    "        \n",
    "        loss = reconstruction_error + KL_divergence + KL_divergence_rot\n",
    "        print(reconstruction_error)\n",
    "        print(KL_divergence)\n",
    "        print(KL_divergence_rot)\n",
    "        print(loss)\n",
    "        \n",
    "        loss_epoch += loss.item()\n",
    "        recon_loss += reconstruction_error.item()\n",
    "        KLD_loss += KL_divergence.item()\n",
    "        KLD_rot_loss += KL_divergence_rot.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == n_epoch-1:\n",
    "            latent_z.extend(z.data.cpu().numpy().tolist())\n",
    "            z_mu.extend(mu.data.cpu().numpy().tolist())\n",
    "            z_logvar.extend(logvar.data.cpu().numpy().tolist())\n",
    "            rot_theta.extend(rot_z.data.cpu().numpy().tolist())\n",
    "            if translation_check:\n",
    "                trans_delta.extend(trans_z.data.cpu().numpy().tolist())\n",
    "            \n",
    "            \n",
    "    if epoch == 0:\n",
    "        print(torch.cuda.memory_summary(device=cuda_device))\n",
    "        \n",
    "    if (epoch+1) % int(n_epoch/10) == 0:\n",
    "        print(tabulate([\n",
    "                        [\"epoch\", epoch+1], \n",
    "                        [\"total loss\", loss_epoch/total_num],\n",
    "                        [\"reconstruction error\", recon_loss/total_num],\n",
    "                        [\"KL divergence\", KLD_loss/total_num],\n",
    "                        [\"KL divergence (rotation)\", KLD_rot_loss/total_num],\n",
    "                        ]))\n",
    "        print(\"%.2f minutes have passed\"%((time.time()-start)/60))\n",
    "        \n",
    "        fig, ax = plt.subplots(2, n_fig, figsize=(5*n_fig, 5*2))\n",
    "        for i in range(n_fig):\n",
    "            if radial_flat_:\n",
    "                tmp = np.zeros((radial_range[1]*2, radial_range[1]*2))\n",
    "                tmp[k_indy, k_indx] = x[i].data.cpu().numpy()\n",
    "                ax[0][i].imshow(tmp, cmap=\"inferno\")\n",
    "                ax[0][i].axis(\"off\")\n",
    "                tmp[k_indy, k_indx] = x_[i].data.cpu().numpy()\n",
    "                ax[1][i].imshow(tmp, cmap=\"inferno\")\n",
    "                ax[1][i].axis(\"off\")\n",
    "                \n",
    "            else:\n",
    "                ax[0][i].imshow(x[i].data.cpu().numpy().reshape(w_size, w_size), cmap=\"inferno\")\n",
    "                ax[0][i].axis(\"off\")\n",
    "                ax[1][i].imshow(x_[i].data.cpu().numpy().reshape(w_size, w_size), cmap=\"inferno\")\n",
    "                ax[1][i].axis(\"off\")\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "latent_z = np.asarray(latent_z)\n",
    "z_mu = np.asarray(z_mu)\n",
    "z_logvar = np.asarray(z_logvar)\n",
    "rot_theta = np.asarray(rot_theta)\n",
    "trans_delta = np.asarray(trans_delta)\n",
    "print(\"The training has been finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad4942-ae99-4e19-aa23-059133329abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = np.zeros_like(latent_z)\n",
    "coeffs[ri] = latent_z.copy()\n",
    "coeffs_reshape = reshape_coeff(coeffs, data_shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.grid()\n",
    "for i in range(num_comp):\n",
    "    ax.hist(coeffs[:, i], bins=50, alpha=(1.0-i*(1/num_comp)))\n",
    "plt.show()\n",
    "\n",
    "if num_img != 1:\n",
    "    for i in range(num_comp):\n",
    "        fig, ax = plt.subplots(1, num_img, figsize=(7*num_img, 7))\n",
    "        for j in range(num_img):\n",
    "            tmp = ax[j].imshow(coeffs_reshape[j][:, :, i], cmap=\"viridis\")\n",
    "            ax[j].axis(\"off\")\n",
    "            #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()\n",
    "else:            \n",
    "    for i in range(num_comp):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7, 7*num_img))\n",
    "        tmp = ax.imshow(coeffs_reshape[0][:, :, i], cmap=\"viridis\")\n",
    "        ax.axis(\"off\")\n",
    "        #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b62050-41fb-4aa8-8a1f-665bca10c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rotation_check:\n",
    "    rot_theta = np.expand_dims(rot_theta, axis=1)\n",
    "    coeffs = np.zeros_like(rot_theta)\n",
    "    coeffs[ri] = rot_theta.copy()\n",
    "    coeffs_reshape = reshape_coeff(coeffs, data_shape)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.grid()\n",
    "    ax.hist(coeffs[:], bins=50, alpha=(1.0-i*(1/num_comp)))\n",
    "    plt.show()\n",
    "\n",
    "    if num_img != 1:\n",
    "        fig, ax = plt.subplots(1, num_img, figsize=(7*num_img, 7))\n",
    "        for j in range(num_img):\n",
    "            tmp = ax[j].imshow(coeffs_reshape[j][:, :], cmap=\"viridis\")\n",
    "            ax[j].axis(\"off\")\n",
    "            #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()\n",
    "    else:            \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7, 7*num_img))\n",
    "        tmp = ax.imshow(coeffs_reshape[0][:, :], cmap=\"viridis\")\n",
    "        ax.axis(\"off\")\n",
    "        #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b452126-4a10-45bb-9879-d1fa7caeec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if translation_check:\n",
    "    trans_delta = np.expand_dims(trans_delta, axis=1)\n",
    "    coeffs = np.zeros_like(trans_delta)\n",
    "    coeffs[ri] = rot_theta.copy()\n",
    "    coeffs_reshape = reshape_coeff(coeffs, data_shape)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.grid()\n",
    "    ax.hist(coeffs[:], bins=50, alpha=(1.0-i*(1/num_comp)))\n",
    "    plt.show()\n",
    "\n",
    "    if num_img != 1:\n",
    "        fig, ax = plt.subplots(1, num_img, figsize=(7*num_img, 7))\n",
    "        for j in range(num_img):\n",
    "            tmp = ax[j].imshow(coeffs_reshape[j][:, :], cmap=\"viridis\")\n",
    "            ax[j].axis(\"off\")\n",
    "            #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()\n",
    "    else:            \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(7, 7*num_img))\n",
    "        tmp = ax.imshow(coeffs_reshape[0][:, :], cmap=\"viridis\")\n",
    "        ax.axis(\"off\")\n",
    "        #fig.colorbar(tmp, cax=fig.add_axes([0.92, 0.15, 0.04, 0.7]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c06bc3-7811-41a0-b469-3a137bfe4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 10\n",
    "sigma = 5.0\n",
    "z_test = np.linspace(-sigma, sigma, n_sample*10, endpoint=True)\n",
    "rv = stats.norm(0, 1)\n",
    "norm_pdf = rv.pdf(z_test)\n",
    "norm_pdf = norm_pdf / np.sum(norm_pdf)\n",
    "z_test = np.sort(np.random.choice(z_test, n_sample, replace=False, p=norm_pdf))\n",
    "z_test = np.meshgrid(z_test, z_test)\n",
    "z_test = np.stack((z_test[0].flatten(), z_test[1].flatten()), axis=1)\n",
    "print(z_test.shape)\n",
    "z_test = torch.from_numpy(z_test).to(torch.float32).to(cuda_device)\n",
    "\n",
    "coord_test = img_coord.expand(n_sample**2, img_coord.size(0), img_coord.size(1))\n",
    "coord_test = coord_test.to(cuda_device)\n",
    "print(coord_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074ae709-a90b-46e6-803f-0214637e2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_model.eval()\n",
    "generated = dec_model(coord_test.contiguous(), z_test)\n",
    "print(generated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d4a7d-19a3-4787-aed3-0b523c876914",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(n_sample, n_sample, figsize=(30, 30))\n",
    "tmp = np.zeros((radial_range[1]*2, radial_range[1]*2))\n",
    "for i, a in enumerate(ax.flat):\n",
    "    tmp[k_indy, k_indx] = generated[i].squeeze().data.cpu().numpy()\n",
    "    a.imshow(tmp, cmap=\"jet\")\n",
    "    a.axis(\"off\")\n",
    "plt.subplots_adjust(hspace=0.01, wspace=0.01)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
